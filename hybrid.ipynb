{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Retrieval System using FAISS and BM25\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a hybrid retrieval system that integrates ***dense retrieval*** using **FAISS** and ***sparse retrieval*** using **BM25**. The system allows us to perform efficient document search by leveraging embeddings from a PDF document. The retrieval results can be compared from both methods, showcasing the benefits of hybrid retrieval in enhancing search relevance.\n",
    "\n",
    "## Features\n",
    "- **Dense Retrieval with FAISS**: Utilizes embeddings generated by the `all-MiniLM-L6-v2` model for efficient vector similarity searches.\n",
    "- **Sparse Retrieval with BM25**: Implements the BM25 algorithm for traditional keyword-based searches.\n",
    "- **Hybrid Retrieval Approach**: Combines results from both methods to provide more relevant search outcomes.\n",
    "- **PDF Support**: Loads content directly from a PDF document for searching.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU semantic-chunkers datasets langchain pypdf faiss-cpu sentence_transformers rank_bm25 nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data (PDF Notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/wassim/Downloads/KubernetesNotes.pdf\"  \n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 0}, page_content=\"Kubernetes For Everyone\\nKubernetes introduction and features\\nHow Kubernetes works?\\nIn Kubernetes, there is a master node and multiple worker nodes, each worker node can handle\\nmultiple pods.\\nPods are just a bunch of containers clustered together as a working unit. You can start designing\\nyour applications using pods.\\nOnce your pods are ready, you can specify pod definitions to the master node, and how many you\\nwant to deploy. From this point, Kubernetes is in control.\\nIt takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes\\nstarts new pods on a functioning worker node.\\nThis makes the process of managing the containers easy and simple.\\nIt makes it easy to build and add more features and improving the application to attain higher\\ncustomer satisfaction.\\nFinally, no matter what technology you're invested in, Kubernetes can help you.\\nImage credits: Source: Knoldus Inc\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 1}, page_content='What is the Master node and Worker node in #Kubernetes?\\nExplained below,\\n#Containerization is the trend that is taking over the world, allowing firms to run any kind of different\\napplications in a variety of different environments. To keep track of all these containers, to schedule,\\nto manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\\nexponentially well.\\nKubernetes is a master-slave type of architecture. It operated with Master node and worker node\\nprinciples.\\nWhat exactly they do?\\nMaster Node:\\n>The main machine that controls the nodes\\n> Main entry point for all administrative tasks\\n> It handles the orchestration of the worker nodes\\nWorker Node:\\n> It is a worker machine in Kubernetes (used to be known as a minion)\\n> This machine performs the requested tasks. The Master Node controls each Node\\n> Runs containers inside pods\\n> This is where the Docker engine runs and takes care of downloading images and starting\\ncontainers\\nKnow in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes-\\nhow-to-get-started/'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 2}, page_content=\"#Containers are the de-facto deployment format of today.\\nBut where does #Kubernetes comes in the play?\\nWhile tools such as #Docker provide the actual containers, we also need tools to take care of things\\nsuch as replication, failovers, orchestration, and that is where Kubernetes comes into play.\\nThe Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only\\nmore reliable, but also much faster, because we’re no longer dealing with VMs.\\nWhen working with Kubernetes, you have to become accustomed with concepts and namings like\\npods, services, and replication controllers. If you're not already familiar yet, no worries, there are\\nsome excellent resources available to learn Kubernetes and get up to speed.\\nSome key features of Kubernetes that make it unique,\\n> Service Discovery\\n> Health Check Capability\\n> Simplified Monitoring\\n> Self-healing\\n> Secret and configuration management\\n> Horizontal scaling\\n> Storage Management\\n> Networking\\n> Services\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 3}, page_content='> ConfigMap and Secret\\n> Logging\\n> Rolling update or rollback\\n> Load balancing\\nWhat feature do you like the most in Kubernetes?\\nBTW, take a look at these tips, tricks, and lessons for taking containerized apps to k8s:\\nhttps://lnkd.in/eZtxx-Z\\nImage credits: TheNewStack\\n#Kubernetes features that we all like:)\\n> Automatic binpacking: This is where Kubernetes helps in automatically placing containers based\\non their resource requirements, limits, and other constraints, without compromising on availability.\\n> Service discovery and load balancing: In simple words, service discovery is the process of figuring\\nout how to connect to a service.\\n>Self-healing: Restarts the containers that fail, replaces, and reschedules containers when nodes die.\\n> Automated rollouts and rollbacks: With this feature, Kubernetes does progressively roll out\\nchanges, and it ensures it doesn’t kill all your instances at the same time.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 4}, page_content='> Secrets and configuration management: Kubernetes has a built-in mechanism of storing\\nconfiguration values that you would prefer to keep private. Sensitive information such as user name,\\npasswords with encryption, and other credentials can be kept confidentially.\\n> Storage orchestration: Automatically mount the storage system of your choice, whether from local\\nstorage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS,\\niSCSI, Gluster, Ceph, Cinder, or Flocker.\\nSee more in the original article: https://lnkd.in/e8MzdeV\\n#Kubernetes helps in easy automation of container lifecycle management.\\nHowever, the concept of Kubernetes is quite complex.\\nHere are the top practices of Kubernetes:)\\n> Dis-allow root users\\n> Dis-allow privileged containers'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 5}, page_content='> Use pod resource limits and requests\\n> Dis-allow new capabilities addition\\n> Dis-allow any changes to the parameters of the kernel\\n> Dis-allow using bin mounts\\n> Use read-only root filesystem\\n> Dis-allow dock socket bind mount access\\n> Dis-allow usage of host ports and networks\\n> Keep smaller base image\\nWhat else? Know more: https://lnkd.in/ejetevG\\n \\n \\n#Kubernetes Core Features.\\n1. Container runtime: Kubernetes uses Container Runtime Interface (CRI) to transparently manage\\nyour containers without necessarily having to know (or deal with) the runtime used.\\n2. The Network Plugin: As we discussed earlier, a container orchestration system is responsible\\n(among other things) for managing the network through which containers and services\\ncommunicate.\\n3. The Volume Plugin: A volume broadly refers to the storage that will be availed for the pod.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 6}, page_content=\"4. Image Registry: Kubernetes must contact an image registry (whether public or private) to be able\\nto pull images and spin out container.\\n5. Cloud Provider: Kubernetes can be deployed on almost any platform you may think of.\\n6. Identity Provider: You can use your own identity provider system to authenticate your users to the\\ncluster as long as it uses OpenID connect. Read this amazing article: https://lnkd.in/eySj5aG\\nKubernetes setup:\\nHow much time can you devote to setting up the #Kubernetes ?\\ue012\\ue013\\ue014\\ue015\\ue016\\ue017\\ue000\\ue000 \\ue00d\\ue00e\\ue00f\\ue010\\ue011\\nThat's the question to ask yourself.\\nBecause installing and setting up Kubernetes can be daunting. Yes!\\nKubernetes itself (meaning the plain, open-source version) does not have a built-in installer, nor does\\nit offer much in the way of one-size-fits-all default configurations. You’ll likelyneed to tweak (or write\\nfrom scratch) a lot of configuration files before you get your cluster up and running smoothly.\\nThus, the process of installing and configuring Kubernetes can be a very daunting one that\\nconsumes many days of work.\\nSome Kubernetes distributions offer interactive installer scripts that help automate much of the\\nsetup process. If you use one of these, setup and installation is easier to accomplish in a day or two.\\nBut it’s still by no means a turnkey process.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 7}, page_content=\"A third option is to run Kubernetes as a managed service in the cloud using a solution like Google\\nKubernetes Engine, but the downside is, you have less choice and control in determining how to\\nconfigure your Kubernetes environment.\\nKnow more on the facts to consider before selecting Kubernetes: bit.ly/KubernetesSetup\\n \\n#Kubernetes autoscaling. How does it work?\\nScaling is an essential operational practice that used to be done manually for a long time concerning\\napplications, with the introduction of tools like Kubernetes, the things have changed dramatically in\\nthe software industry.\\nIn the context of the Kubernetes cluster, there are typically two things you would like to scale as a\\nuser, Pods, and Nodes.\\nThere are three types of scaling:\\n> HorizontalPodAutoscaler\\n> VerticalPodAutoscaler, and\\n> Cluster Autoscaler.\\nWith these techniques, Kubernetes can take intelligent scaling decisions automatically.\\nHorizontalPodAutoscaler refers to increasing the number of Pods serving the application, in\\nresponse to the present computational needs.\\nVerticalPodAutoscaler involves expanding the resources of the Pods.\\nCluster Autoscaler (CA) scales your node clusters based on the number of pending pods. It checks\\nto see whether there are any pending pods and increases the size of the cluster so that these pods\\ncan be created.\\nMastering autoscaling needs some patience and persistent efforts to see which technique suits your\\napp's needs by doing trial and error.\\nContinuous learning and experimentation is the key:)\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 8}, page_content='More or less #Kubernetes clusters.\\nHow to decide?\\nKubernetes is devised as a highly available cluster of computers that are connected to work as a\\nsingle unit for more power and efficiency.\\nThe cluster forms the heart of Kubernetes: It can schedule and run containers across a group of\\nmachines, be they physical or virtual, on-premises or in the cloud.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 9}, page_content='A Kubernetes cluster is formed out of 2 types of resources:\\n> Master is coordinating the cluster\\n> Nodes are where we run applications\\nKubernetes is still a bit of sophisticated technology and has a steep learning curve, even after a\\ncouple of years working with it, you’ll stillwonder if you got it all under control.\\nBut when your company asks you to decide on using and implementing Kubernetes, one question\\nyou will have is, deciding on the Kubernetes clusters.\\nMy friend Sander has written an amazing article on this, take a look - https://lnkd.in/eSC5vpa\\nKubernetes security:\\nKeep your clusters updated with the latest #Kubernetes security patches.\\nSee how and why...\\nJust like any application, Kubernetes is continuously updating new features and security updates.\\nHence, it is imperative that the underlying nodes and Kubernetes clusters need to be in parallel and\\nup to date as well.\\nThe standard “zonal” KubernetesEngine clusters will have only one master node backing them, but\\nyou can create “regional” clusters that provide multi-zone feature, highly available masters. One\\ncrucial thing to remember here is, while creating a cluster, be sure to select the “regional”option.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 10}, page_content='By using Kubernetes Engine, you can keep your Kubernetes cluster up to date with just a few clicks.\\nIt is highly recommended to use Kubernetes Engine regional clusters for the high-availability masters\\nand automatic node upgrades to have a hassle-free upgrade experience.\\n(Source: cloud.google.com )\\nSee my in-depth article on Kubernetes security best practices: https://lnkd.in/eZq9mGs\\nIn 2018, a severe vulnerability in #Kubernetes (CVE-2018–1002105) was\\ndisclosed...\\nThis vulnerability allowed an unauthorized and unauthenticated user to gain full admin privileges on\\na cluster and perform privilege escalation.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 11}, page_content=\"In one more incident, a security firm RedLock said that hackers accessed one of Tesla’s Amazon\\ncloud accounts, and they used it to run cryptocurrency-mining malware. The initial point of entry for\\nthe Tesla cloud breach was an unsecured administrative console for Kubernetes.\\nSo many scary stories!\\nDo you know how important is security in Kubernetes?\\nKnow here in my in-depth article - https://lnkd.in/ecviJ6c\\n'Role-Based Access Control' is one of the security best practices in\\n#Kubernetes .\\nKnow more about it below...\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 12}, page_content='RBAC allows Kubernetes architects to specify which types of actions are permitted for a user and\\nwhat kind of tasks they are going to perform depending on their role in the organization This is\\nhow you create roles based on the different kinds of access your users and applications need to\\nvarious resources, and later assign only the required and minimum permissions for appropriate\\naccess to the roles. Minimum or restricting access to only specified and well-identified users who\\nmust perform defined actions on a resource is critical in securing your cluster and is one of the\\nsecurity best practices. To tighten the security and ease handling a large number of accounts,\\nRBAC makes use of an intermediate item called binding. Via role binding mechanism, you can\\ncreate “roles,” which will have a set of capabilities, then assign eachuser one or more roles. For\\nexample, some users might just have permission to list pods, and some other users may have\\npermission to get, list, watch, create, update, patch, delete pods. Writing an article on this and will\\nbe out soon.\\n[No doubt, It is highly challenging to embrace #CloudNative and#DevOps in\\nregulated industries.\\nAs#microservices and container-based infrastructure are enriching how the software is built these\\ndays, new challenges with security and compliance appear for regulated firms.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 13}, page_content='Regulated industries imply several challenges\\n> Strong restrictions on secured networks\\n> Fine-grained audit trails\\n> Strong ACLs models\\n> Full lifecycle governance\\n> Integration with 3rd parties\\nHere is an example where Artem Semenov from Align Technology is showing us the basic\\nrequirements for making #K8S compliant with sensitive data handling regulations and possible\\ntechnical solutions - https://lnkd.in/g2G-rFX\\nKubernetes case studies:\\nDelivering Pizza with #Kubernetes ?\\nDomino’s #CloudNative story is mind-blowing. Read:)'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 14}, page_content='The company makes splashy headlines with ambitions to deliver pizzas with driverless cars and\\ndrones, along with AI and other automation processes. Domino’s currently offers 15 digital ways to\\norder pizza.\\nHow does Domino’s deliver so many new solutions, features, and updates, while it’s hot? By\\ncultivating an experimental culture of cloud-native innovation within the company.\\nApplications play a significant role in Domino’s business strategy.\\nDomino’s intends to create new business value and speed their time to market by rewriting core\\napplications to run as microservices.\\nDominos teams are modernizing these core applications in-house with microservices, but each team\\nuses a different platform.\\nThe in-house teams chose a comprehensive, production-grade Kubernetes distribution platform with\\nenterprise security features and full lifecycle management support and with Kubernetes, Domino’s is\\nevaluating the feasibility and level of effort to convert current systems and processes to a container-\\nbased architecture.\\nRead the full story: https://lnkd.in/eZzagGH\\nKubernetes best practices for taking your containers all the way to production: https://lnkd.in/eZtxx-\\nZ'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 15}, page_content=\"How did Airbnb enable 1,000+ engineers with #Kubernetes ?\\nThis is the talk summary of Melanie Cebula at Qcon London. About the way her team wraps\\nKubernetes into easy-to-consume internal services for its development teams.\\nInstead of creating a set of dreaded YAML files per environment, development teams need only\\nprovide their project-specific, service-focused inputs and then run the internal service kube-gen\\n(alias k gen).\\nThis simple command takes care of generating all the required YAML files, ensuring their\\ncorrectness, and finally applying them in the corresponding Kubernetes cluster(s).\\nThe infrastructure team at Airbnb is saving hundreds, if not thousands, of hours for 1,000+ engineers\\nwho can now use a much simpler abstraction that has been adapted to their needs, with a user\\nexperience that's familiar to them.\\nKnow more about this story at: https://lnkd.in/egDqpHE\\nThe figure above shows the kube-gen wrapper generates the needed configuration files per\\nenvironment at Airbnb. Source: Melanie Cebula, Airbnb.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 16}, page_content=\"A 50-year-old audio company using #Kubernetes ?\\nThat's insane. Read:)\\nIt supports rapid development for millions of #IoT products with Kubernetes. How?\\nBose has been a big player in helping IoT devices and audio enabling systems for several years.\\nBose engineering leadership team always wanted to move to a microservices architecture.\\nWhen the demand started growing, they had to look for a solution that can help their engineering\\nplatform team to deploy services to production quickly without any hassle. For this, they evaluated\\nand found many alternative platforms but finally chose Kubernetes due to its scaled IoT platform-as-\\na-service running on AWS and vibrant community aspect.\\nThey launched a revised platform along with Prometheus, An open-source monitoring system to\\nserve more than 3 million connected IoT devices. Today, Bose has over 1,800 namespaces and 340\\nworker nodes in one of its live production clusters. Bose has more than 100 engineers working on\\nthis platform already, this platform is helping them make 30,000 nonproduction deployments every\\nyear.\\nRead the original story: https://lnkd.in/eJgBRHN\\nAlso, take a look at this video on CI/CD enablement for connected device products with OTA\\ncapabilities: http://bit.ly/IoTCICD\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 17}, page_content=\"Amadeus's lift and shift to #Kubernetes .\\nAn inspiring #CloudNative story for you. Read.....\\nAmadeus had two choices: Either pour more concrete and extend the data center or move the\\nworkload to the cloud & this made them go with Google Cloud.\\nSo within 18 months, Amadeus had lifted and shifted one of their most critical application 'Master\\nPricer' to the Google Cloud Platform.\\nNow you know, the next step for them was to move to Kubernetes since it made more sense with\\nGoogle Cloud Platform.\\nThe aim is, they wanted to go faster with Kubernetes, and the challenge was to add a disciplinary\\npolicy of learning Kubernetes across the team.\\nSo, the team at Amadeus started learning how to operate Kubernetes and how to monitor it, do\\nalerting.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 18}, page_content=\"During the migration, Amadeus had engineers from both Google and Red Hat on site to help them\\nget to grips with OpenShift and the container orchestration technology Kubernetes.\\nThe overall goal for Amadeus is to move all production workloads to run on a single operating model\\nwith Kubernetes.\\nThe company now feels it made the right bet.\\nCredits:\\nhttps://lnkd.in/gS3n_vy\\nhttp://bit.ly/AmadeusGCP\\n#Kubernetes has helped Adidas to deploy faster, safer, with more quality\\nand scale quickly.\\nRead further...\\nAdidas understood the importance of Kubernetes over VMs, and now their tech stack is wholly\\npowered by Kubernetes. Before creating a VM would take days or even weeks that would impact the\\ndevelopers' productivity and the business overall.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 19}, page_content=\"Kubernetes helped Adidas to get rid of the overhead that comes with a VM-based infrastructure.\\nDeployments that used to take four to five days can now be deployed four to five times a day with\\nthe help of Kubernetes. Currently, Adidas has over 4,000 pods running on Kubernetes, achieving the\\nvelocity it needs to develop applications faster than ever.\\nTheir lead infrastructure engineers say that, it is easy to set up and configure the new tool, but the\\nproblem comes in scaling.\\nThey also stressed on the point that training is essential for engineers working on the platform.\\nSource credits: TechGenix\\n \\n#Kubernetes is sexy because it attracts modern engineers that care about\\n#CloudNative technologies.\\ue008 \\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\\nRead how News UK utilized the power of Kubernetes to save itself in the cloud-native world.\\nThe critical goal for News UK was to be better able to scale up its environment around breaking\\nnews events & unpredictable reader volumes.\\nThey thought if VMs can help them, but soon they realized that VMs take long to spin up and when\\nthere is a spike of traffic, it is not fast enough to bring new capacity into the AutoScalingGroup\\n(that's what Marcin Cuber, a former cloud DevOps engineer at News UK has to say)\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 20}, page_content=\"They adopted Docker and Kubernetes. Docker containers running in Kubernetes are smaller and\\nlightweight, and they can easily help to scale up or scale down as required.\\nCuber also had some advice for any organization looking to adopt Docker and Kubernetes.\\n> make your Docker images as small as possible and to focus on running stateless applications with\\nKubernetes\\n> run health checks for your applications and to use YAML to deploy anything\\nNews UK also wanted to cut cloud costs, so they paired EKS clusters with AWS spot instances, and\\nthey also used AWS Lambda to make this work efficiently.\\nThe full case study: https://lnkd.in/e4iAq2r\\nA banking app's must-read story of running #Kubernetes in production.\\nA journey that affirms you don't have to be too big to use Kubernetes.\\nThey started their #CloudNative journey by splitting the massive monolith application into smaller\\nmicroservices.\\nTo spin up these microservices, they used Ansible, Terraform, and Jenkins and to deploy these\\nmicroservices as a whole unit (as shown in the image).\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 21}, page_content=\"Then they suddenly started to experience some of the scaling issues with Microservices. So, they\\ndidn't get any of the microservices benefits. Hence they started looking for ways to get out of this\\ncomplexity by shifting their focus from machine-oriented to application-oriented architecture.\\nThey chose Kubernetes as the abstraction layer along with AWS, not worrying about where the\\ncontainers are running, and this is how they were able to manage microservices and unlocked the\\nvelocity of microservices. They also chose Kubernetes from a security perspective and to specify\\nhow the applications should run.\\nNow they run around 80+ microservices now in production with the help of Kubernetes:)\\nWatch and learn how they did it in this video 'Running Kubernetes in production at Lunar Way by\\nKasper Nissen.' - https://lnkd.in/eU9s3JX\\nWhy did eBay choose #Kubernetes ?\\nDaily, eBay handles 300 billion data queries & a massive amount of data that’s above 500 petabytes.\\neBay has to move massive amounts of data & manage the traffic, keeping in mind a smooth user\\nexperience while still ensuring a secure, stable environment that’s flexible enough to encourage\\ninnovation.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 22}, page_content=\"In the fall of 2018, the company announced they were in the midst of a three-year plan they called\\n“re-platforming.”\\neBay's 90% of cloud technology was dependent on OpenStack, and they are in the move to ditch\\nOpenStack altogether.\\neBay is “re-platforming, itself with Kubernetes, Docker, & Apache Kafka, a stream processing\\nplatform that increases data handling and decreases latency.\\nThe goal is to improve the user experience and to promote productivity with their engineers and\\nprogrammers & completely revamp its data center infrastructure.\\nThe other activities in this re-platforming include designing their own custom servers and rolling out\\na new, decentralized strategy for their data centers. Like Facebook & Microsoft, eBay is relying on\\nopen-sourcing to design their custom servers.\\nSuch an inspiring case study.\\nBloomberg is one of the first companies to adopt #Kubernetes .\\nThey used Kubernetes into production in 2017.\\nThe aim was to bring up new applications and services to users as fast as possible and free up\\ndevelopers from operational tasks. After evaluating many offerings from different firms, they\\nselected Kubernetes as they thought it aligned exactly with what they were trying to solve.\\nOne of the key aims at Bloomberg was to make better use of existing hardware investments using\\ndifferent features of Kubernetes. As a result, they were able to very efficiently use the hardware to\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 23}, page_content=\"the point where they could get close to 90 to 95 percent utilization rates (as per Andrey Rybka, head\\nof the compute infrastructure team at Bloomberg)\\nNothing great comes easy; Kubernetes makes many things simpler only if you know how to use it.\\nAs the developers initially found it challenging to use, the teams had many training programs around\\nKubernetes at Bloomberg.\\nShopify's #Kubernetes journey is just minded blowing:)\\nShopify was one of the pioneers in large-scale users of #Docker in production. They ran 100% of\\ntheir production traffic in hundreds of containers. Shopify engineering team saw the real value of\\ncontainerization and also aspired to introduce a real orchestration layer.\\nThey started looking at orchestration solutions, and the technology behind Kubernetes fascinated\\nthem.\\nIt all started in 2016, where all the engineers were happy running services everywhere with a simple\\nstack that included Chef, Docker, AWS, and Heroku. But just like any other company that is in the\\ngrowth phase, the Shopify encountered some challenges when this Canadian e-commerce company\\nsaw 80k+ requests per second during peak demand. Wohooo:)\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 24}, page_content=\"Many processes were not scalable, and they needed a quick solution. The Shopify team recognized\\nthat they needed to increase their focus on tested infrastructure and automation that works as\\nexpected, every time.\\nThe Shopify engineering team believed in three principles: providing a 'paved road, 'hide complexity'\\nand 'self-serve.'\\nRead this fascinating story here: https://lnkd.in/eN34vAm\\nAll credits to Niko Kurtti, QCon & InfoQ.\\nBox’s #Kubernetes journey is one of the finest #CloudNative inspirations. Read…\\nA few years ago at Box, it was taking up to six months to build a new\\n#microservice .\\nFast forward to today, it takes only a couple of days.\\nHow did they manage to speed up? Two key factors made it possible,\\n1. Kubernetes technology\\n2. DevOps practices\\nFounded in 2005, Box was a monolithic PHP application and had grown over time to millions of lines\\nof code. The monolithic nature of their application led to them basically building very tightly coupled\\ndesigns, and this tight coupling was coming in their way. It was resulting in them not being able to\\ninnovate as quickly as they wanted to.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 25}, page_content=\"Bugs in one part of their application would require them to roll back the entire application. So many\\nengineers working on the same code base with millions of lines of code, bugs were not that\\nuncommon. It was increasingly hard to ship features or even bug fixes on time. So they looked out\\nfor a solution and decided to go with the microservices approach. But then they started to face\\nanother set of problems....That's where Kubernetes came in:)\\nSee the full video talk by Kunal Parmar, Senior Engineering Manager at Box: https://lnkd.in/etnJTbE\\nI hope you all are #GoT fans here...\\nLet me tell you the #Kubernetes story at HBO!\\nThe engineers started panicking as they knew the unpredictable traffic for the most anticipated\\nGame of Thrones season seven premiere is going to be HUGE.\\nOne of the challenges they found out was the under-utilization of the deployed resources.\\nNode.js code tends only to use a single CPU core.\\nAWS EC2 instances that had excellent networking capabilities tended to be based on dual-core\\nCPUs.\\nAs such, HBO was only using 50 percent of the deployed CPU capacity across its deployment. The\\nability to spin up new instances on EC2 wasn't quite as fast as what HBO needed.\\nHBO also found that in times of peak demand for Game of Thrones, it was also running out of\\navailable IP addresses to help deliver the content to viewers.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 26}, page_content='\"We went from not running a single service inside of a container to hosting all of Games of Thrones\\nseason 7 with Kubernetes,\" Illya Chekrygin, Senior Staff Engineer at HBO told the KubeCon audience.\\nAt last, the HBO chose Kubernetes among other alternatives, basically because of its vibrant and\\nactive community.\\nCredits: KubeCon 2017, eWEEK\\nItaly\\'s biggest traditional bank is embracing #Kubernetes ?\\nA conventional bank running its real business on such a young technology?\\nNo way, are you kidding me?\\nNope, I am not kidding. Italy\\'s banking group, Intesa Sanpaolo, has made this transition.\\nThese are banks who still run their ATM networks on 30-year-old mainframe technology, and\\nembracing the hottest trend & tech is nearly unbelievable. Even though ING, the banking and\\nfinancial corporation, changed the way the banks were seen by upgrading itself with Kubernetes and\\n#DevOps practices very early in the game, there was still a stigma with adopting Kubernetes in the\\nhighly regulated and controlled environments like Healthcare, Banks, etc.\\nThe bank\\'s engineering team came up with an initiative strategy in 2018 to throw away the old way\\nof thinking and started embracing the technologies like microservices, container architecture, and\\nmigrate from monolithic to multi-tier applications. It was transforming itself into a software\\ncompany, unbelievable.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 27}, page_content=\"Today the bank runs more than 3,000 applications. Of those, more than 120 are now running in\\nproduction using the new microservices architecture, including two of the 10 most business-critical\\nfor the bank.\\nRead the full case here: https://lnkd.in/e_c5fbg\\nHow did 'Pokemon Go' able to scale so efficiently?\\nThe answer is #Kubernetes . Read the story...\\n500+ million downloads and 20+ million daily active users. That's HUGE.\\nPokemon Go engineers never thought their user base would increase exponentially surpassing the\\nexpectations within a short time. Even the servers couldn't handle this much traffic.\\nThe Challenge:\\nThe horizontal scaling on one side but Pokemon Go also faced a severe challenge when it came to\\nvertical scaling because of the real-time activity by millions of users worldwide. Niantic was not\\nprepared for this.\\nThe Solution:\\nThe magic of containers. The application logic for the game ran on Google Container Engine (GKE)\\npowered by the open-source Kubernetes project.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 28}, page_content=\"Niantic chose GKE for its ability to orchestrate their container cluster at planetary-scale, freeing its\\nteam to focus on deploying live changes for their players. In this way, Niantic used Google Cloud to\\nturn Pokémon GO into a service for millions of players, continuously adapting and improving. This\\ngot them more time to concentrate on building the game's application logic and new features rather\\nthan worrying about the scaling part.\\n“Going Viral” is not always easy to predict but you can always have Kubernetes in your tech stack.\\nCI/CD with Kubernetes:\\nHow can you quickly achieve CI/CD automation with #Kubernetes and roll it out across your\\norganization?\\nStep 1: Develop your microservice using dependencies from registries that are proxied in Artifactory.\\nThe resulting App package can be a .war or .jar file.\\nStep 2: Create a Docker Framework using Tomcat and Java-8 on Ubuntu as a base image. Push this\\nimage to a Docker registry in Artifactory, where it is also scanned by Xray to assure security and\\nlicense compliance.\\nStep 3: Create the Docker image for the microservice by adding the .war/.jar file to the Docker\\nFramework, and push the image to a Docker registry in Artifactory, where it is scanned by Xray.\\nStep 4: Create a Helm chart for the microservice, and push it to a Helm repository in Artifactory.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 29}, page_content='Step 5: Deploy the microservice from the secure Docker registry to the Kubernetes cluster using the\\nHelm Chart.\\nSee the in-depth article: https://lnkd.in/e4Vkc3m\\nSurvey and findings:\\n#Kubernetes usage in production is skyrocketing\\ue018 \\ue019\\ue01a\\ue01b\\ue01c\\ue01d\\ue01e\\ue01f \\nWhat else?\\nHere are 15 interesting takeaways from the #CNCF annual survey.'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 30}, page_content=\"All information and source credit goes to CNCF - https://lnkd.in/eD9fN2R\\nand Janakiram MSV's article here: https://lnkd.in/eb6GNZS\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 31}, page_content=\"Tips and tricks:\\n#Kubernetes is the ultimate avatar of cloud-native development.\\nHere are some tips and tricks shared by Timothy Josefik on HackerNoon.\\nThe whole article is here: https://lnkd.in/eGdmrkR\\n#Kubernetes has become a synonym for #CloudNative tech.\\nMore and more companies are trying to use Kubernetes in production, and that's a good move.\\nTake a look at these 10 Kubernetes production checklist.\"),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 32}, page_content='-----------------------------------------------------------------------------------------------------------------------------------------------------------------\\nFree resources:'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 33}, page_content='Learn a new skill while working from home!\\nSharing some free #Kubernetes resources for everyone.\\n> Kubernetes the hard way: https://lnkd.in/eu_rkry\\n> Introduction to Kubernetes: https://lnkd.in/ebHEyaY\\n> Learn Kubernetes by Playing the “Game of Pods”: https://lnkd.in/epGmpd9\\n> Kubernetes by example: https://lnkd.in/eETkYKW\\n> Getting started with Kubernetes: https://lnkd.in/eqD8qWA\\n> Kubernetes hands-on labs: https://lnkd.in/eEgfyDG\\n> Learning path - Kubernetes: https://lnkd.in/ea5H-WH\\n> Fundamentals of Containers, Kubernetes, and Red Hat OpenShift: https://lnkd.in/ea_tfrt\\n> Zero to hero with Kubernetes: https://lnkd.in/eJJRjck'),\n",
       " Document(metadata={'source': '/home/wassim/Downloads/KubernetesNotes.pdf', 'page': 34}, page_content='That is it:)\\nAll credits to Kubernetes for helping companies scale and win big time.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = [page.page_content for page in pages]\n",
    "content = ' '.join(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kubernetes For Everyone\\nKubernetes introduction and features\\nHow Kubernetes works?\\nIn Kubernetes, there is a master node and multiple worker nodes, each worker node can handle\\nmultiple pods.\\nPods are just a bunch of containers clustered together as a working unit. You can start designing\\nyour applications using pods.\\nOnce your pods are ready, you can specify pod definitions to the master node, and how many you\\nwant to deploy. From this point, Kubernetes is in control.\\nIt takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes\\nstarts new pods on a functioning worker node.\\nThis makes the process of managing the containers easy and simple.\\nIt makes it easy to build and add more features and improving the application to attain higher\\ncustomer satisfaction.\\nFinally, no matter what technology you\\'re invested in, Kubernetes can help you.\\nImage credits: Source: Knoldus Inc What is the Master node and Worker node in #Kubernetes?\\nExplained below,\\n#Containerization is the trend that is taking over the world, allowing firms to run any kind of different\\napplications in a variety of different environments. To keep track of all these containers, to schedule,\\nto manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\\nexponentially well.\\nKubernetes is a master-slave type of architecture. It operated with Master node and worker node\\nprinciples.\\nWhat exactly they do?\\nMaster Node:\\n>The main machine that controls the nodes\\n> Main entry point for all administrative tasks\\n> It handles the orchestration of the worker nodes\\nWorker Node:\\n> It is a worker machine in Kubernetes (used to be known as a minion)\\n> This machine performs the requested tasks. The Master Node controls each Node\\n> Runs containers inside pods\\n> This is where the Docker engine runs and takes care of downloading images and starting\\ncontainers\\nKnow in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes-\\nhow-to-get-started/ #Containers are the de-facto deployment format of today.\\nBut where does #Kubernetes comes in the play?\\nWhile tools such as #Docker provide the actual containers, we also need tools to take care of things\\nsuch as replication, failovers, orchestration, and that is where Kubernetes comes into play.\\nThe Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only\\nmore reliable, but also much faster, because we’re no longer dealing with VMs.\\nWhen working with Kubernetes, you have to become accustomed with concepts and namings like\\npods, services, and replication controllers. If you\\'re not already familiar yet, no worries, there are\\nsome excellent resources available to learn Kubernetes and get up to speed.\\nSome key features of Kubernetes that make it unique,\\n> Service Discovery\\n> Health Check Capability\\n> Simplified Monitoring\\n> Self-healing\\n> Secret and configuration management\\n> Horizontal scaling\\n> Storage Management\\n> Networking\\n> Services > ConfigMap and Secret\\n> Logging\\n> Rolling update or rollback\\n> Load balancing\\nWhat feature do you like the most in Kubernetes?\\nBTW, take a look at these tips, tricks, and lessons for taking containerized apps to k8s:\\nhttps://lnkd.in/eZtxx-Z\\nImage credits: TheNewStack\\n#Kubernetes features that we all like:)\\n> Automatic binpacking: This is where Kubernetes helps in automatically placing containers based\\non their resource requirements, limits, and other constraints, without compromising on availability.\\n> Service discovery and load balancing: In simple words, service discovery is the process of figuring\\nout how to connect to a service.\\n>Self-healing: Restarts the containers that fail, replaces, and reschedules containers when nodes die.\\n> Automated rollouts and rollbacks: With this feature, Kubernetes does progressively roll out\\nchanges, and it ensures it doesn’t kill all your instances at the same time. > Secrets and configuration management: Kubernetes has a built-in mechanism of storing\\nconfiguration values that you would prefer to keep private. Sensitive information such as user name,\\npasswords with encryption, and other credentials can be kept confidentially.\\n> Storage orchestration: Automatically mount the storage system of your choice, whether from local\\nstorage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS,\\niSCSI, Gluster, Ceph, Cinder, or Flocker.\\nSee more in the original article: https://lnkd.in/e8MzdeV\\n#Kubernetes helps in easy automation of container lifecycle management.\\nHowever, the concept of Kubernetes is quite complex.\\nHere are the top practices of Kubernetes:)\\n> Dis-allow root users\\n> Dis-allow privileged containers > Use pod resource limits and requests\\n> Dis-allow new capabilities addition\\n> Dis-allow any changes to the parameters of the kernel\\n> Dis-allow using bin mounts\\n> Use read-only root filesystem\\n> Dis-allow dock socket bind mount access\\n> Dis-allow usage of host ports and networks\\n> Keep smaller base image\\nWhat else? Know more: https://lnkd.in/ejetevG\\n \\n \\n#Kubernetes Core Features.\\n1. Container runtime: Kubernetes uses Container Runtime Interface (CRI) to transparently manage\\nyour containers without necessarily having to know (or deal with) the runtime used.\\n2. The Network Plugin: As we discussed earlier, a container orchestration system is responsible\\n(among other things) for managing the network through which containers and services\\ncommunicate.\\n3. The Volume Plugin: A volume broadly refers to the storage that will be availed for the pod. 4. Image Registry: Kubernetes must contact an image registry (whether public or private) to be able\\nto pull images and spin out container.\\n5. Cloud Provider: Kubernetes can be deployed on almost any platform you may think of.\\n6. Identity Provider: You can use your own identity provider system to authenticate your users to the\\ncluster as long as it uses OpenID connect. Read this amazing article: https://lnkd.in/eySj5aG\\nKubernetes setup:\\nHow much time can you devote to setting up the #Kubernetes ?\\ue012\\ue013\\ue014\\ue015\\ue016\\ue017\\ue000\\ue000 \\ue00d\\ue00e\\ue00f\\ue010\\ue011\\nThat\\'s the question to ask yourself.\\nBecause installing and setting up Kubernetes can be daunting. Yes!\\nKubernetes itself (meaning the plain, open-source version) does not have a built-in installer, nor does\\nit offer much in the way of one-size-fits-all default configurations. You’ll likelyneed to tweak (or write\\nfrom scratch) a lot of configuration files before you get your cluster up and running smoothly.\\nThus, the process of installing and configuring Kubernetes can be a very daunting one that\\nconsumes many days of work.\\nSome Kubernetes distributions offer interactive installer scripts that help automate much of the\\nsetup process. If you use one of these, setup and installation is easier to accomplish in a day or two.\\nBut it’s still by no means a turnkey process. A third option is to run Kubernetes as a managed service in the cloud using a solution like Google\\nKubernetes Engine, but the downside is, you have less choice and control in determining how to\\nconfigure your Kubernetes environment.\\nKnow more on the facts to consider before selecting Kubernetes: bit.ly/KubernetesSetup\\n \\n#Kubernetes autoscaling. How does it work?\\nScaling is an essential operational practice that used to be done manually for a long time concerning\\napplications, with the introduction of tools like Kubernetes, the things have changed dramatically in\\nthe software industry.\\nIn the context of the Kubernetes cluster, there are typically two things you would like to scale as a\\nuser, Pods, and Nodes.\\nThere are three types of scaling:\\n> HorizontalPodAutoscaler\\n> VerticalPodAutoscaler, and\\n> Cluster Autoscaler.\\nWith these techniques, Kubernetes can take intelligent scaling decisions automatically.\\nHorizontalPodAutoscaler refers to increasing the number of Pods serving the application, in\\nresponse to the present computational needs.\\nVerticalPodAutoscaler involves expanding the resources of the Pods.\\nCluster Autoscaler (CA) scales your node clusters based on the number of pending pods. It checks\\nto see whether there are any pending pods and increases the size of the cluster so that these pods\\ncan be created.\\nMastering autoscaling needs some patience and persistent efforts to see which technique suits your\\napp\\'s needs by doing trial and error.\\nContinuous learning and experimentation is the key:) More or less #Kubernetes clusters.\\nHow to decide?\\nKubernetes is devised as a highly available cluster of computers that are connected to work as a\\nsingle unit for more power and efficiency.\\nThe cluster forms the heart of Kubernetes: It can schedule and run containers across a group of\\nmachines, be they physical or virtual, on-premises or in the cloud. A Kubernetes cluster is formed out of 2 types of resources:\\n> Master is coordinating the cluster\\n> Nodes are where we run applications\\nKubernetes is still a bit of sophisticated technology and has a steep learning curve, even after a\\ncouple of years working with it, you’ll stillwonder if you got it all under control.\\nBut when your company asks you to decide on using and implementing Kubernetes, one question\\nyou will have is, deciding on the Kubernetes clusters.\\nMy friend Sander has written an amazing article on this, take a look - https://lnkd.in/eSC5vpa\\nKubernetes security:\\nKeep your clusters updated with the latest #Kubernetes security patches.\\nSee how and why...\\nJust like any application, Kubernetes is continuously updating new features and security updates.\\nHence, it is imperative that the underlying nodes and Kubernetes clusters need to be in parallel and\\nup to date as well.\\nThe standard “zonal” KubernetesEngine clusters will have only one master node backing them, but\\nyou can create “regional” clusters that provide multi-zone feature, highly available masters. One\\ncrucial thing to remember here is, while creating a cluster, be sure to select the “regional”option. By using Kubernetes Engine, you can keep your Kubernetes cluster up to date with just a few clicks.\\nIt is highly recommended to use Kubernetes Engine regional clusters for the high-availability masters\\nand automatic node upgrades to have a hassle-free upgrade experience.\\n(Source: cloud.google.com )\\nSee my in-depth article on Kubernetes security best practices: https://lnkd.in/eZq9mGs\\nIn 2018, a severe vulnerability in #Kubernetes (CVE-2018–1002105) was\\ndisclosed...\\nThis vulnerability allowed an unauthorized and unauthenticated user to gain full admin privileges on\\na cluster and perform privilege escalation. In one more incident, a security firm RedLock said that hackers accessed one of Tesla’s Amazon\\ncloud accounts, and they used it to run cryptocurrency-mining malware. The initial point of entry for\\nthe Tesla cloud breach was an unsecured administrative console for Kubernetes.\\nSo many scary stories!\\nDo you know how important is security in Kubernetes?\\nKnow here in my in-depth article - https://lnkd.in/ecviJ6c\\n\\'Role-Based Access Control\\' is one of the security best practices in\\n#Kubernetes .\\nKnow more about it below... RBAC allows Kubernetes architects to specify which types of actions are permitted for a user and\\nwhat kind of tasks they are going to perform depending on their role in the organization This is\\nhow you create roles based on the different kinds of access your users and applications need to\\nvarious resources, and later assign only the required and minimum permissions for appropriate\\naccess to the roles. Minimum or restricting access to only specified and well-identified users who\\nmust perform defined actions on a resource is critical in securing your cluster and is one of the\\nsecurity best practices. To tighten the security and ease handling a large number of accounts,\\nRBAC makes use of an intermediate item called binding. Via role binding mechanism, you can\\ncreate “roles,” which will have a set of capabilities, then assign eachuser one or more roles. For\\nexample, some users might just have permission to list pods, and some other users may have\\npermission to get, list, watch, create, update, patch, delete pods. Writing an article on this and will\\nbe out soon.\\n[No doubt, It is highly challenging to embrace #CloudNative and#DevOps in\\nregulated industries.\\nAs#microservices and container-based infrastructure are enriching how the software is built these\\ndays, new challenges with security and compliance appear for regulated firms. Regulated industries imply several challenges\\n> Strong restrictions on secured networks\\n> Fine-grained audit trails\\n> Strong ACLs models\\n> Full lifecycle governance\\n> Integration with 3rd parties\\nHere is an example where Artem Semenov from Align Technology is showing us the basic\\nrequirements for making #K8S compliant with sensitive data handling regulations and possible\\ntechnical solutions - https://lnkd.in/g2G-rFX\\nKubernetes case studies:\\nDelivering Pizza with #Kubernetes ?\\nDomino’s #CloudNative story is mind-blowing. Read:) The company makes splashy headlines with ambitions to deliver pizzas with driverless cars and\\ndrones, along with AI and other automation processes. Domino’s currently offers 15 digital ways to\\norder pizza.\\nHow does Domino’s deliver so many new solutions, features, and updates, while it’s hot? By\\ncultivating an experimental culture of cloud-native innovation within the company.\\nApplications play a significant role in Domino’s business strategy.\\nDomino’s intends to create new business value and speed their time to market by rewriting core\\napplications to run as microservices.\\nDominos teams are modernizing these core applications in-house with microservices, but each team\\nuses a different platform.\\nThe in-house teams chose a comprehensive, production-grade Kubernetes distribution platform with\\nenterprise security features and full lifecycle management support and with Kubernetes, Domino’s is\\nevaluating the feasibility and level of effort to convert current systems and processes to a container-\\nbased architecture.\\nRead the full story: https://lnkd.in/eZzagGH\\nKubernetes best practices for taking your containers all the way to production: https://lnkd.in/eZtxx-\\nZ How did Airbnb enable 1,000+ engineers with #Kubernetes ?\\nThis is the talk summary of Melanie Cebula at Qcon London. About the way her team wraps\\nKubernetes into easy-to-consume internal services for its development teams.\\nInstead of creating a set of dreaded YAML files per environment, development teams need only\\nprovide their project-specific, service-focused inputs and then run the internal service kube-gen\\n(alias k gen).\\nThis simple command takes care of generating all the required YAML files, ensuring their\\ncorrectness, and finally applying them in the corresponding Kubernetes cluster(s).\\nThe infrastructure team at Airbnb is saving hundreds, if not thousands, of hours for 1,000+ engineers\\nwho can now use a much simpler abstraction that has been adapted to their needs, with a user\\nexperience that\\'s familiar to them.\\nKnow more about this story at: https://lnkd.in/egDqpHE\\nThe figure above shows the kube-gen wrapper generates the needed configuration files per\\nenvironment at Airbnb. Source: Melanie Cebula, Airbnb. A 50-year-old audio company using #Kubernetes ?\\nThat\\'s insane. Read:)\\nIt supports rapid development for millions of #IoT products with Kubernetes. How?\\nBose has been a big player in helping IoT devices and audio enabling systems for several years.\\nBose engineering leadership team always wanted to move to a microservices architecture.\\nWhen the demand started growing, they had to look for a solution that can help their engineering\\nplatform team to deploy services to production quickly without any hassle. For this, they evaluated\\nand found many alternative platforms but finally chose Kubernetes due to its scaled IoT platform-as-\\na-service running on AWS and vibrant community aspect.\\nThey launched a revised platform along with Prometheus, An open-source monitoring system to\\nserve more than 3 million connected IoT devices. Today, Bose has over 1,800 namespaces and 340\\nworker nodes in one of its live production clusters. Bose has more than 100 engineers working on\\nthis platform already, this platform is helping them make 30,000 nonproduction deployments every\\nyear.\\nRead the original story: https://lnkd.in/eJgBRHN\\nAlso, take a look at this video on CI/CD enablement for connected device products with OTA\\ncapabilities: http://bit.ly/IoTCICD Amadeus\\'s lift and shift to #Kubernetes .\\nAn inspiring #CloudNative story for you. Read.....\\nAmadeus had two choices: Either pour more concrete and extend the data center or move the\\nworkload to the cloud & this made them go with Google Cloud.\\nSo within 18 months, Amadeus had lifted and shifted one of their most critical application \\'Master\\nPricer\\' to the Google Cloud Platform.\\nNow you know, the next step for them was to move to Kubernetes since it made more sense with\\nGoogle Cloud Platform.\\nThe aim is, they wanted to go faster with Kubernetes, and the challenge was to add a disciplinary\\npolicy of learning Kubernetes across the team.\\nSo, the team at Amadeus started learning how to operate Kubernetes and how to monitor it, do\\nalerting. During the migration, Amadeus had engineers from both Google and Red Hat on site to help them\\nget to grips with OpenShift and the container orchestration technology Kubernetes.\\nThe overall goal for Amadeus is to move all production workloads to run on a single operating model\\nwith Kubernetes.\\nThe company now feels it made the right bet.\\nCredits:\\nhttps://lnkd.in/gS3n_vy\\nhttp://bit.ly/AmadeusGCP\\n#Kubernetes has helped Adidas to deploy faster, safer, with more quality\\nand scale quickly.\\nRead further...\\nAdidas understood the importance of Kubernetes over VMs, and now their tech stack is wholly\\npowered by Kubernetes. Before creating a VM would take days or even weeks that would impact the\\ndevelopers\\' productivity and the business overall. Kubernetes helped Adidas to get rid of the overhead that comes with a VM-based infrastructure.\\nDeployments that used to take four to five days can now be deployed four to five times a day with\\nthe help of Kubernetes. Currently, Adidas has over 4,000 pods running on Kubernetes, achieving the\\nvelocity it needs to develop applications faster than ever.\\nTheir lead infrastructure engineers say that, it is easy to set up and configure the new tool, but the\\nproblem comes in scaling.\\nThey also stressed on the point that training is essential for engineers working on the platform.\\nSource credits: TechGenix\\n \\n#Kubernetes is sexy because it attracts modern engineers that care about\\n#CloudNative technologies.\\ue008 \\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\\nRead how News UK utilized the power of Kubernetes to save itself in the cloud-native world.\\nThe critical goal for News UK was to be better able to scale up its environment around breaking\\nnews events & unpredictable reader volumes.\\nThey thought if VMs can help them, but soon they realized that VMs take long to spin up and when\\nthere is a spike of traffic, it is not fast enough to bring new capacity into the AutoScalingGroup\\n(that\\'s what Marcin Cuber, a former cloud DevOps engineer at News UK has to say) They adopted Docker and Kubernetes. Docker containers running in Kubernetes are smaller and\\nlightweight, and they can easily help to scale up or scale down as required.\\nCuber also had some advice for any organization looking to adopt Docker and Kubernetes.\\n> make your Docker images as small as possible and to focus on running stateless applications with\\nKubernetes\\n> run health checks for your applications and to use YAML to deploy anything\\nNews UK also wanted to cut cloud costs, so they paired EKS clusters with AWS spot instances, and\\nthey also used AWS Lambda to make this work efficiently.\\nThe full case study: https://lnkd.in/e4iAq2r\\nA banking app\\'s must-read story of running #Kubernetes in production.\\nA journey that affirms you don\\'t have to be too big to use Kubernetes.\\nThey started their #CloudNative journey by splitting the massive monolith application into smaller\\nmicroservices.\\nTo spin up these microservices, they used Ansible, Terraform, and Jenkins and to deploy these\\nmicroservices as a whole unit (as shown in the image). Then they suddenly started to experience some of the scaling issues with Microservices. So, they\\ndidn\\'t get any of the microservices benefits. Hence they started looking for ways to get out of this\\ncomplexity by shifting their focus from machine-oriented to application-oriented architecture.\\nThey chose Kubernetes as the abstraction layer along with AWS, not worrying about where the\\ncontainers are running, and this is how they were able to manage microservices and unlocked the\\nvelocity of microservices. They also chose Kubernetes from a security perspective and to specify\\nhow the applications should run.\\nNow they run around 80+ microservices now in production with the help of Kubernetes:)\\nWatch and learn how they did it in this video \\'Running Kubernetes in production at Lunar Way by\\nKasper Nissen.\\' - https://lnkd.in/eU9s3JX\\nWhy did eBay choose #Kubernetes ?\\nDaily, eBay handles 300 billion data queries & a massive amount of data that’s above 500 petabytes.\\neBay has to move massive amounts of data & manage the traffic, keeping in mind a smooth user\\nexperience while still ensuring a secure, stable environment that’s flexible enough to encourage\\ninnovation. In the fall of 2018, the company announced they were in the midst of a three-year plan they called\\n“re-platforming.”\\neBay\\'s 90% of cloud technology was dependent on OpenStack, and they are in the move to ditch\\nOpenStack altogether.\\neBay is “re-platforming, itself with Kubernetes, Docker, & Apache Kafka, a stream processing\\nplatform that increases data handling and decreases latency.\\nThe goal is to improve the user experience and to promote productivity with their engineers and\\nprogrammers & completely revamp its data center infrastructure.\\nThe other activities in this re-platforming include designing their own custom servers and rolling out\\na new, decentralized strategy for their data centers. Like Facebook & Microsoft, eBay is relying on\\nopen-sourcing to design their custom servers.\\nSuch an inspiring case study.\\nBloomberg is one of the first companies to adopt #Kubernetes .\\nThey used Kubernetes into production in 2017.\\nThe aim was to bring up new applications and services to users as fast as possible and free up\\ndevelopers from operational tasks. After evaluating many offerings from different firms, they\\nselected Kubernetes as they thought it aligned exactly with what they were trying to solve.\\nOne of the key aims at Bloomberg was to make better use of existing hardware investments using\\ndifferent features of Kubernetes. As a result, they were able to very efficiently use the hardware to the point where they could get close to 90 to 95 percent utilization rates (as per Andrey Rybka, head\\nof the compute infrastructure team at Bloomberg)\\nNothing great comes easy; Kubernetes makes many things simpler only if you know how to use it.\\nAs the developers initially found it challenging to use, the teams had many training programs around\\nKubernetes at Bloomberg.\\nShopify\\'s #Kubernetes journey is just minded blowing:)\\nShopify was one of the pioneers in large-scale users of #Docker in production. They ran 100% of\\ntheir production traffic in hundreds of containers. Shopify engineering team saw the real value of\\ncontainerization and also aspired to introduce a real orchestration layer.\\nThey started looking at orchestration solutions, and the technology behind Kubernetes fascinated\\nthem.\\nIt all started in 2016, where all the engineers were happy running services everywhere with a simple\\nstack that included Chef, Docker, AWS, and Heroku. But just like any other company that is in the\\ngrowth phase, the Shopify encountered some challenges when this Canadian e-commerce company\\nsaw 80k+ requests per second during peak demand. Wohooo:) Many processes were not scalable, and they needed a quick solution. The Shopify team recognized\\nthat they needed to increase their focus on tested infrastructure and automation that works as\\nexpected, every time.\\nThe Shopify engineering team believed in three principles: providing a \\'paved road, \\'hide complexity\\'\\nand \\'self-serve.\\'\\nRead this fascinating story here: https://lnkd.in/eN34vAm\\nAll credits to Niko Kurtti, QCon & InfoQ.\\nBox’s #Kubernetes journey is one of the finest #CloudNative inspirations. Read…\\nA few years ago at Box, it was taking up to six months to build a new\\n#microservice .\\nFast forward to today, it takes only a couple of days.\\nHow did they manage to speed up? Two key factors made it possible,\\n1. Kubernetes technology\\n2. DevOps practices\\nFounded in 2005, Box was a monolithic PHP application and had grown over time to millions of lines\\nof code. The monolithic nature of their application led to them basically building very tightly coupled\\ndesigns, and this tight coupling was coming in their way. It was resulting in them not being able to\\ninnovate as quickly as they wanted to. Bugs in one part of their application would require them to roll back the entire application. So many\\nengineers working on the same code base with millions of lines of code, bugs were not that\\nuncommon. It was increasingly hard to ship features or even bug fixes on time. So they looked out\\nfor a solution and decided to go with the microservices approach. But then they started to face\\nanother set of problems....That\\'s where Kubernetes came in:)\\nSee the full video talk by Kunal Parmar, Senior Engineering Manager at Box: https://lnkd.in/etnJTbE\\nI hope you all are #GoT fans here...\\nLet me tell you the #Kubernetes story at HBO!\\nThe engineers started panicking as they knew the unpredictable traffic for the most anticipated\\nGame of Thrones season seven premiere is going to be HUGE.\\nOne of the challenges they found out was the under-utilization of the deployed resources.\\nNode.js code tends only to use a single CPU core.\\nAWS EC2 instances that had excellent networking capabilities tended to be based on dual-core\\nCPUs.\\nAs such, HBO was only using 50 percent of the deployed CPU capacity across its deployment. The\\nability to spin up new instances on EC2 wasn\\'t quite as fast as what HBO needed.\\nHBO also found that in times of peak demand for Game of Thrones, it was also running out of\\navailable IP addresses to help deliver the content to viewers. \"We went from not running a single service inside of a container to hosting all of Games of Thrones\\nseason 7 with Kubernetes,\" Illya Chekrygin, Senior Staff Engineer at HBO told the KubeCon audience.\\nAt last, the HBO chose Kubernetes among other alternatives, basically because of its vibrant and\\nactive community.\\nCredits: KubeCon 2017, eWEEK\\nItaly\\'s biggest traditional bank is embracing #Kubernetes ?\\nA conventional bank running its real business on such a young technology?\\nNo way, are you kidding me?\\nNope, I am not kidding. Italy\\'s banking group, Intesa Sanpaolo, has made this transition.\\nThese are banks who still run their ATM networks on 30-year-old mainframe technology, and\\nembracing the hottest trend & tech is nearly unbelievable. Even though ING, the banking and\\nfinancial corporation, changed the way the banks were seen by upgrading itself with Kubernetes and\\n#DevOps practices very early in the game, there was still a stigma with adopting Kubernetes in the\\nhighly regulated and controlled environments like Healthcare, Banks, etc.\\nThe bank\\'s engineering team came up with an initiative strategy in 2018 to throw away the old way\\nof thinking and started embracing the technologies like microservices, container architecture, and\\nmigrate from monolithic to multi-tier applications. It was transforming itself into a software\\ncompany, unbelievable. Today the bank runs more than 3,000 applications. Of those, more than 120 are now running in\\nproduction using the new microservices architecture, including two of the 10 most business-critical\\nfor the bank.\\nRead the full case here: https://lnkd.in/e_c5fbg\\nHow did \\'Pokemon Go\\' able to scale so efficiently?\\nThe answer is #Kubernetes . Read the story...\\n500+ million downloads and 20+ million daily active users. That\\'s HUGE.\\nPokemon Go engineers never thought their user base would increase exponentially surpassing the\\nexpectations within a short time. Even the servers couldn\\'t handle this much traffic.\\nThe Challenge:\\nThe horizontal scaling on one side but Pokemon Go also faced a severe challenge when it came to\\nvertical scaling because of the real-time activity by millions of users worldwide. Niantic was not\\nprepared for this.\\nThe Solution:\\nThe magic of containers. The application logic for the game ran on Google Container Engine (GKE)\\npowered by the open-source Kubernetes project. Niantic chose GKE for its ability to orchestrate their container cluster at planetary-scale, freeing its\\nteam to focus on deploying live changes for their players. In this way, Niantic used Google Cloud to\\nturn Pokémon GO into a service for millions of players, continuously adapting and improving. This\\ngot them more time to concentrate on building the game\\'s application logic and new features rather\\nthan worrying about the scaling part.\\n“Going Viral” is not always easy to predict but you can always have Kubernetes in your tech stack.\\nCI/CD with Kubernetes:\\nHow can you quickly achieve CI/CD automation with #Kubernetes and roll it out across your\\norganization?\\nStep 1: Develop your microservice using dependencies from registries that are proxied in Artifactory.\\nThe resulting App package can be a .war or .jar file.\\nStep 2: Create a Docker Framework using Tomcat and Java-8 on Ubuntu as a base image. Push this\\nimage to a Docker registry in Artifactory, where it is also scanned by Xray to assure security and\\nlicense compliance.\\nStep 3: Create the Docker image for the microservice by adding the .war/.jar file to the Docker\\nFramework, and push the image to a Docker registry in Artifactory, where it is scanned by Xray.\\nStep 4: Create a Helm chart for the microservice, and push it to a Helm repository in Artifactory. Step 5: Deploy the microservice from the secure Docker registry to the Kubernetes cluster using the\\nHelm Chart.\\nSee the in-depth article: https://lnkd.in/e4Vkc3m\\nSurvey and findings:\\n#Kubernetes usage in production is skyrocketing\\ue018 \\ue019\\ue01a\\ue01b\\ue01c\\ue01d\\ue01e\\ue01f \\nWhat else?\\nHere are 15 interesting takeaways from the #CNCF annual survey. All information and source credit goes to CNCF - https://lnkd.in/eD9fN2R\\nand Janakiram MSV\\'s article here: https://lnkd.in/eb6GNZS Tips and tricks:\\n#Kubernetes is the ultimate avatar of cloud-native development.\\nHere are some tips and tricks shared by Timothy Josefik on HackerNoon.\\nThe whole article is here: https://lnkd.in/eGdmrkR\\n#Kubernetes has become a synonym for #CloudNative tech.\\nMore and more companies are trying to use Kubernetes in production, and that\\'s a good move.\\nTake a look at these 10 Kubernetes production checklist. -----------------------------------------------------------------------------------------------------------------------------------------------------------------\\nFree resources: Learn a new skill while working from home!\\nSharing some free #Kubernetes resources for everyone.\\n> Kubernetes the hard way: https://lnkd.in/eu_rkry\\n> Introduction to Kubernetes: https://lnkd.in/ebHEyaY\\n> Learn Kubernetes by Playing the “Game of Pods”: https://lnkd.in/epGmpd9\\n> Kubernetes by example: https://lnkd.in/eETkYKW\\n> Getting started with Kubernetes: https://lnkd.in/eqD8qWA\\n> Kubernetes hands-on labs: https://lnkd.in/eEgfyDG\\n> Learning path - Kubernetes: https://lnkd.in/ea5H-WH\\n> Fundamentals of Containers, Kubernetes, and Red Hat OpenShift: https://lnkd.in/ea_tfrt\\n> Zero to hero with Kubernetes: https://lnkd.in/eJJRjck That is it:)\\nAll credits to Kubernetes for helping companies scale and win big time.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Embedding Model (all-MiniLM-L6-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HuggingFaceEncoder(name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking the Data Semantically using: Statistical Chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = StatisticalChunker(\n",
    "    encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-20 11:12:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 300. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker(docs=[content])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 133, triggered by: 0.21\n",
      "\u001b[31mKubernetes For Everyone Kubernetes introduction and features How Kubernetes works? In Kubernetes, there is a master node and multiple worker nodes, each worker node can handle multiple pods. Pods are just a bunch of containers clustered together as a working unit. You can start designing your applications using pods. Once your pods are ready, you can specify pod definitions to the master node, and how many you want to deploy. From this point, Kubernetes is in control. It takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes starts new pods on a functioning worker node. This makes the process of managing the containers easy and simple.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 123, triggered by: 0.12\n",
      "\u001b[32mIt makes it easy to build and add more features and improving the application to attain higher customer satisfaction. Finally, no matter what technology you're invested in, Kubernetes can help you. Image credits: Source: Knoldus Inc What is the Master node and Worker node in #Kubernetes? Explained below, #Containerization is the trend that is taking over the world, allowing firms to run any kind of different applications in a variety of different environments. To keep track of all these containers, to schedule, to manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 229, triggered by: 0.26\n",
      "\u001b[34mexponentially well. Kubernetes is a master-slave type of architecture. It operated with Master node and worker node principles. What exactly they do? Master Node: >The main machine that controls the nodes > Main entry point for all administrative tasks > It handles the orchestration of the worker nodes Worker Node: > It is a worker machine in Kubernetes (used to be known as a minion) > This machine performs the requested tasks. The Master Node controls each Node > Runs containers inside pods > This is where the Docker engine runs and takes care of downloading images and starting containers Know in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes- how-to-get-started/ #Containers are the de-facto deployment format of today. But where does #Kubernetes comes in the play? While tools such as #Docker provide the actual containers, we also need tools to take care of things such as replication, failovers, orchestration, and that is where Kubernetes comes into play. The Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 158, triggered by: 0.09\n",
      "\u001b[35mmore reliable, but also much faster, because we’re no longer dealing with VMs. When working with Kubernetes, you have to become accustomed with concepts and namings like pods, services, and replication controllers. If you're not already familiar yet, no worries, there are some excellent resources available to learn Kubernetes and get up to speed. Some key features of Kubernetes that make it unique, > Service Discovery > Health Check Capability > Simplified Monitoring > Self-healing > Secret and configuration management > Horizontal scaling > Storage Management > Networking > Services > ConfigMap and Secret > Logging > Rolling update or rollback > Load balancing What feature do you like the most in Kubernetes? BTW, take a look at these tips, tricks, and lessons for taking containerized apps to k8s:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 163, triggered by: 0.10\n",
      "\u001b[31mhttps://lnkd.in/eZtxx-Z Image credits: TheNewStack #Kubernetes features that we all like:) > Automatic binpacking: This is where Kubernetes helps in automatically placing containers based on their resource requirements, limits, and other constraints, without compromising on availability. > Service discovery and load balancing: In simple words, service discovery is the process of figuring out how to connect to a service. >Self-healing: Restarts the containers that fail, replaces, and reschedules containers when nodes die. > Automated rollouts and rollbacks: With this feature, Kubernetes does progressively roll out changes, and it ensures it doesn’t kill all your instances at the same time. > Secrets and configuration management: Kubernetes has a built-in mechanism of storing configuration values that you would prefer to keep private.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 125, triggered by: 0.09\n",
      "\u001b[32mSensitive information such as user name, passwords with encryption, and other credentials can be kept confidentially. > Storage orchestration: Automatically mount the storage system of your choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS, iSCSI, Gluster, Ceph, Cinder, or Flocker. See more in the original article: https://lnkd.in/e8MzdeV #Kubernetes helps in easy automation of container lifecycle management. However, the concept of Kubernetes is quite complex. Here are the top practices of Kubernetes:)\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 133, triggered by: 0.13\n",
      "\u001b[34m> Dis-allow root users > Dis-allow privileged containers > Use pod resource limits and requests > Dis-allow new capabilities addition > Dis-allow any changes to the parameters of the kernel > Dis-allow using bin mounts > Use read-only root filesystem > Dis-allow dock socket bind mount access > Dis-allow usage of host ports and networks > Keep smaller base image What else? Know more: https://lnkd.in/ejetevG #Kubernetes Core Features. 1. Container runtime: Kubernetes uses Container Runtime Interface (CRI) to transparently manage your containers without necessarily having to know (or deal with) the runtime used. 2.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 133, triggered by: 0.15\n",
      "\u001b[35mThe Network Plugin: As we discussed earlier, a container orchestration system is responsible (among other things) for managing the network through which containers and services communicate. 3. The Volume Plugin: A volume broadly refers to the storage that will be availed for the pod. 4. Image Registry: Kubernetes must contact an image registry (whether public or private) to be able to pull images and spin out container. 5. Cloud Provider: Kubernetes can be deployed on almost any platform you may think of. 6. Identity Provider: You can use your own identity provider system to authenticate your users to the cluster as long as it uses OpenID connect.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 132, triggered by: 0.09\n",
      "\u001b[31mRead this amazing article: https://lnkd.in/eySj5aG Kubernetes setup: How much time can you devote to setting up the #Kubernetes ?  That's the question to ask yourself. Because installing and setting up Kubernetes can be daunting. Yes! Kubernetes itself (meaning the plain, open-source version) does not have a built-in installer, nor does it offer much in the way of one-size-fits-all default configurations.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 163, triggered by: 0.06\n",
      "\u001b[32mYou’ll likelyneed to tweak (or write from scratch) a lot of configuration files before you get your cluster up and running smoothly. Thus, the process of installing and configuring Kubernetes can be a very daunting one that consumes many days of work. Some Kubernetes distributions offer interactive installer scripts that help automate much of the setup process. If you use one of these, setup and installation is easier to accomplish in a day or two. But it’s still by no means a turnkey process. A third option is to run Kubernetes as a managed service in the cloud using a solution like Google Kubernetes Engine, but the downside is, you have less choice and control in determining how to configure your Kubernetes environment. Know more on the facts to consider before selecting Kubernetes: bit.ly/KubernetesSetup #Kubernetes autoscaling.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 124, triggered by: 0.10\n",
      "\u001b[34mHow does it work? Scaling is an essential operational practice that used to be done manually for a long time concerning applications, with the introduction of tools like Kubernetes, the things have changed dramatically in the software industry. In the context of the Kubernetes cluster, there are typically two things you would like to scale as a user, Pods, and Nodes. There are three types of scaling: > HorizontalPodAutoscaler > VerticalPodAutoscaler, and > Cluster Autoscaler. With these techniques, Kubernetes can take intelligent scaling decisions automatically. HorizontalPodAutoscaler refers to increasing the number of Pods serving the application, in\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 104, triggered by: 0.08\n",
      "\u001b[35mresponse to the present computational needs. VerticalPodAutoscaler involves expanding the resources of the Pods. Cluster Autoscaler (CA) scales your node clusters based on the number of pending pods. It checks to see whether there are any pending pods and increases the size of the cluster so that these pods can be created. Mastering autoscaling needs some patience and persistent efforts to see which technique suits your app's needs by doing trial and error. Continuous learning and experimentation is the key:) More or less #Kubernetes clusters.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 111, triggered by: 0.09\n",
      "\u001b[31mHow to decide? Kubernetes is devised as a highly available cluster of computers that are connected to work as a single unit for more power and efficiency. The cluster forms the heart of Kubernetes: It can schedule and run containers across a group of machines, be they physical or virtual, on-premises or in the cloud. A Kubernetes cluster is formed out of 2 types of resources: > Master is coordinating the cluster > Nodes are where we run applications Kubernetes is still a bit of sophisticated technology and has a steep learning curve, even after a\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 175, triggered by: 0.01\n",
      "\u001b[32mcouple of years working with it, you’ll stillwonder if you got it all under control. But when your company asks you to decide on using and implementing Kubernetes, one question you will have is, deciding on the Kubernetes clusters. My friend Sander has written an amazing article on this, take a look - https://lnkd.in/eSC5vpa Kubernetes security: Keep your clusters updated with the latest #Kubernetes security patches. See how and why. . . Just like any application, Kubernetes is continuously updating new features and security updates. Hence, it is imperative that the underlying nodes and Kubernetes clusters need to be in parallel and up to date as well. The standard “zonal” KubernetesEngine clusters will have only one master node backing them, but you can create “regional” clusters that provide multi-zone feature, highly available masters.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 125, triggered by: 0.09\n",
      "\u001b[34mOne crucial thing to remember here is, while creating a cluster, be sure to select the “regional”option. By using Kubernetes Engine, you can keep your Kubernetes cluster up to date with just a few clicks. It is highly recommended to use Kubernetes Engine regional clusters for the high-availability masters and automatic node upgrades to have a hassle-free upgrade experience. (Source: cloud.google.com ) See my in-depth article on Kubernetes security best practices: https://lnkd.in/eZq9mGs In 2018, a severe vulnerability in #Kubernetes (CVE-2018–1002105) was\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 136, triggered by: 0.11\n",
      "\u001b[35mdisclosed. . . This vulnerability allowed an unauthorized and unauthenticated user to gain full admin privileges on a cluster and perform privilege escalation. In one more incident, a security firm RedLock said that hackers accessed one of Tesla’s Amazon cloud accounts, and they used it to run cryptocurrency-mining malware. The initial point of entry for the Tesla cloud breach was an unsecured administrative console for Kubernetes. So many scary stories! Do you know how important is security in Kubernetes? Know here in my in-depth article - https://lnkd.in/ecviJ6c 'Role-Based Access Control' is one of the security best practices in #Kubernetes . Know more about it below.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 17, tokens 122, triggered by: 0.17\n",
      "\u001b[31m. . RBAC allows Kubernetes architects to specify which types of actions are permitted for a user and what kind of tasks they are going to perform depending on their role in the organization This is how you create roles based on the different kinds of access your users and applications need to various resources, and later assign only the required and minimum permissions for appropriate access to the roles. Minimum or restricting access to only specified and well-identified users who must perform defined actions on a resource is critical in securing your cluster and is one of the security best practices. To tighten the security and ease handling a large number of accounts,\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 18, tokens 164, triggered by: 0.17\n",
      "\u001b[32mRBAC makes use of an intermediate item called binding. Via role binding mechanism, you can create “roles,” which will have a set of capabilities, then assign eachuser one or more roles. For example, some users might just have permission to list pods, and some other users may have permission to get, list, watch, create, update, patch, delete pods. Writing an article on this and will be out soon. [No doubt, It is highly challenging to embrace #CloudNative and#DevOps in regulated industries. As#microservices and container-based infrastructure are enriching how the software is built these days, new challenges with security and compliance appear for regulated firms. Regulated industries imply several challenges > Strong restrictions on secured networks > Fine-grained audit trails > Strong ACLs models > Full lifecycle governance\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 19, tokens 140, triggered by: 0.15\n",
      "\u001b[34m> Integration with 3rd parties Here is an example where Artem Semenov from Align Technology is showing us the basic requirements for making #K8S compliant with sensitive data handling regulations and possible technical solutions - https://lnkd.in/g2G-rFX Kubernetes case studies: Delivering Pizza with #Kubernetes ? Domino’s #CloudNative story is mind-blowing. Read:) The company makes splashy headlines with ambitions to deliver pizzas with driverless cars and drones, along with AI and other automation processes. Domino’s currently offers 15 digital ways to order pizza. How does Domino’s deliver so many new solutions, features, and updates, while it’s hot?\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 20, tokens 123, triggered by: 0.07\n",
      "\u001b[35mBy cultivating an experimental culture of cloud-native innovation within the company. Applications play a significant role in Domino’s business strategy. Domino’s intends to create new business value and speed their time to market by rewriting core applications to run as microservices. Dominos teams are modernizing these core applications in-house with microservices, but each team uses a different platform. The in-house teams chose a comprehensive, production-grade Kubernetes distribution platform with enterprise security features and full lifecycle management support and with Kubernetes, Domino’s is evaluating the feasibility and level of effort to convert current systems and processes to a container- based architecture.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 21, tokens 154, triggered by: 0.15\n",
      "\u001b[31mRead the full story: https://lnkd.in/eZzagGH Kubernetes best practices for taking your containers all the way to production: https://lnkd.in/eZtxx- Z How did Airbnb enable 1,000+ engineers with #Kubernetes ? This is the talk summary of Melanie Cebula at Qcon London. About the way her team wraps Kubernetes into easy-to-consume internal services for its development teams. Instead of creating a set of dreaded YAML files per environment, development teams need only provide their project-specific, service-focused inputs and then run the internal service kube-gen (alias k gen). This simple command takes care of generating all the required YAML files, ensuring their correctness, and finally applying them in the corresponding Kubernetes cluster(s).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 22, tokens 299, triggered by: 0.04\n",
      "\u001b[32mThe infrastructure team at Airbnb is saving hundreds, if not thousands, of hours for 1,000+ engineers who can now use a much simpler abstraction that has been adapted to their needs, with a user experience that's familiar to them. Know more about this story at: https://lnkd.in/egDqpHE The figure above shows the kube-gen wrapper generates the needed configuration files per environment at Airbnb. Source: Melanie Cebula, Airbnb. A 50-year-old audio company using #Kubernetes ? That's insane. Read:) It supports rapid development for millions of #IoT products with Kubernetes. How? Bose has been a big player in helping IoT devices and audio enabling systems for several years. Bose engineering leadership team always wanted to move to a microservices architecture. When the demand started growing, they had to look for a solution that can help their engineering platform team to deploy services to production quickly without any hassle. For this, they evaluated and found many alternative platforms but finally chose Kubernetes due to its scaled IoT platform-as- a-service running on AWS and vibrant community aspect. They launched a revised platform along with Prometheus, An open-source monitoring system to serve more than 3 million connected IoT devices. Today, Bose has over 1,800 namespaces and 340 worker nodes in one of its live production clusters. Bose has more than 100 engineers working on this platform already, this platform is helping them make 30,000 nonproduction deployments every\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 23, tokens 273, triggered by: 0.08\n",
      "\u001b[34myear. Read the original story: https://lnkd.in/eJgBRHN Also, take a look at this video on CI/CD enablement for connected device products with OTA capabilities: http://bit.ly/IoTCICD Amadeus's lift and shift to #Kubernetes . An inspiring #CloudNative story for you. Read. . . . . Amadeus had two choices: Either pour more concrete and extend the data center or move the workload to the cloud & this made them go with Google Cloud. So within 18 months, Amadeus had lifted and shifted one of their most critical application 'Master Pricer' to the Google Cloud Platform. Now you know, the next step for them was to move to Kubernetes since it made more sense with Google Cloud Platform. The aim is, they wanted to go faster with Kubernetes, and the challenge was to add a disciplinary policy of learning Kubernetes across the team. So, the team at Amadeus started learning how to operate Kubernetes and how to monitor it, do alerting. During the migration, Amadeus had engineers from both Google and Red Hat on site to help them get to grips with OpenShift and the container orchestration technology Kubernetes. The overall goal for Amadeus is to move all production workloads to run on a single operating model with Kubernetes.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 24, tokens 284, triggered by: token limit\n",
      "\u001b[35mThe company now feels it made the right bet. Credits: https://lnkd.in/gS3n_vy http://bit.ly/AmadeusGCP #Kubernetes has helped Adidas to deploy faster, safer, with more quality and scale quickly. Read further. . . Adidas understood the importance of Kubernetes over VMs, and now their tech stack is wholly powered by Kubernetes. Before creating a VM would take days or even weeks that would impact the developers' productivity and the business overall. Kubernetes helped Adidas to get rid of the overhead that comes with a VM-based infrastructure. Deployments that used to take four to five days can now be deployed four to five times a day with the help of Kubernetes. Currently, Adidas has over 4,000 pods running on Kubernetes, achieving the velocity it needs to develop applications faster than ever. Their lead infrastructure engineers say that, it is easy to set up and configure the new tool, but the problem comes in scaling. They also stressed on the point that training is essential for engineers working on the platform. Source credits: TechGenix #Kubernetes is sexy because it attracts modern engineers that care about #CloudNative technologies. \u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 25, tokens 290, triggered by: token limit\n",
      "\u001b[31mRead how News UK utilized the power of Kubernetes to save itself in the cloud-native world. The critical goal for News UK was to be better able to scale up its environment around breaking news events & unpredictable reader volumes. They thought if VMs can help them, but soon they realized that VMs take long to spin up and when there is a spike of traffic, it is not fast enough to bring new capacity into the AutoScalingGroup (that's what Marcin Cuber, a former cloud DevOps engineer at News UK has to say) They adopted Docker and Kubernetes. Docker containers running in Kubernetes are smaller and lightweight, and they can easily help to scale up or scale down as required. Cuber also had some advice for any organization looking to adopt Docker and Kubernetes. > make your Docker images as small as possible and to focus on running stateless applications with Kubernetes > run health checks for your applications and to use YAML to deploy anything News UK also wanted to cut cloud costs, so they paired EKS clusters with AWS spot instances, and they also used AWS Lambda to make this work efficiently. The full case study: https://lnkd.in/e4iAq2r A banking app's must-read story of running #Kubernetes in production. A journey that affirms you don't have to be too big to use Kubernetes. They started their #CloudNative journey by splitting the massive monolith application into smaller microservices.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 26, tokens 181, triggered by: 0.13\n",
      "\u001b[32mTo spin up these microservices, they used Ansible, Terraform, and Jenkins and to deploy these microservices as a whole unit (as shown in the image). Then they suddenly started to experience some of the scaling issues with Microservices. So, they didn't get any of the microservices benefits. Hence they started looking for ways to get out of this complexity by shifting their focus from machine-oriented to application-oriented architecture. They chose Kubernetes as the abstraction layer along with AWS, not worrying about where the containers are running, and this is how they were able to manage microservices and unlocked the velocity of microservices. They also chose Kubernetes from a security perspective and to specify how the applications should run. Now they run around 80+ microservices now in production with the help of Kubernetes:) Watch and learn how they did it in this video 'Running Kubernetes in production at Lunar Way by\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 27, tokens 172, triggered by: 0.22\n",
      "\u001b[34mKasper Nissen.' - https://lnkd.in/eU9s3JX Why did eBay choose #Kubernetes ? Daily, eBay handles 300 billion data queries & a massive amount of data that’s above 500 petabytes. eBay has to move massive amounts of data & manage the traffic, keeping in mind a smooth user experience while still ensuring a secure, stable environment that’s flexible enough to encourage innovation. In the fall of 2018, the company announced they were in the midst of a three-year plan they called “re-platforming.” eBay's 90% of cloud technology was dependent on OpenStack, and they are in the move to ditch OpenStack altogether. eBay is “re-platforming, itself with Kubernetes, Docker, & Apache Kafka, a stream processing platform that increases data handling and decreases latency.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 28, tokens 292, triggered by: 0.15\n",
      "\u001b[35mThe goal is to improve the user experience and to promote productivity with their engineers and programmers & completely revamp its data center infrastructure. The other activities in this re-platforming include designing their own custom servers and rolling out a new, decentralized strategy for their data centers. Like Facebook & Microsoft, eBay is relying on open-sourcing to design their custom servers. Such an inspiring case study. Bloomberg is one of the first companies to adopt #Kubernetes . They used Kubernetes into production in 2017. The aim was to bring up new applications and services to users as fast as possible and free up developers from operational tasks. After evaluating many offerings from different firms, they selected Kubernetes as they thought it aligned exactly with what they were trying to solve. One of the key aims at Bloomberg was to make better use of existing hardware investments using different features of Kubernetes. As a result, they were able to very efficiently use the hardware to the point where they could get close to 90 to 95 percent utilization rates (as per Andrey Rybka, head of the compute infrastructure team at Bloomberg) Nothing great comes easy; Kubernetes makes many things simpler only if you know how to use it. As the developers initially found it challenging to use, the teams had many training programs around Kubernetes at Bloomberg. Shopify's #Kubernetes journey is just minded blowing:) Shopify was one of the pioneers in large-scale users of #Docker in production.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 29, tokens 159, triggered by: 0.15\n",
      "\u001b[31mThey ran 100% of their production traffic in hundreds of containers. Shopify engineering team saw the real value of containerization and also aspired to introduce a real orchestration layer. They started looking at orchestration solutions, and the technology behind Kubernetes fascinated them. It all started in 2016, where all the engineers were happy running services everywhere with a simple stack that included Chef, Docker, AWS, and Heroku. But just like any other company that is in the growth phase, the Shopify encountered some challenges when this Canadian e-commerce company saw 80k+ requests per second during peak demand. Wohooo:) Many processes were not scalable, and they needed a quick solution. The Shopify team recognized that they needed to increase their focus on tested infrastructure and automation that works as\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 30, tokens 130, triggered by: 0.11\n",
      "\u001b[32mexpected, every time. The Shopify engineering team believed in three principles: providing a 'paved road, 'hide complexity' and 'self-serve.' Read this fascinating story here: https://lnkd.in/eN34vAm All credits to Niko Kurtti, QCon & InfoQ. Box’s #Kubernetes journey is one of the finest #CloudNative inspirations. Read… A few years ago at Box, it was taking up to six months to build a new #microservice . Fast forward to today, it takes only a couple of days. How did they manage to speed up? Two key factors made it possible,\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 31, tokens 100, triggered by: 0.11\n",
      "\u001b[34m1. Kubernetes technology 2. DevOps practices Founded in 2005, Box was a monolithic PHP application and had grown over time to millions of lines of code. The monolithic nature of their application led to them basically building very tightly coupled designs, and this tight coupling was coming in their way. It was resulting in them not being able to innovate as quickly as they wanted to. Bugs in one part of their application would require them to roll back the entire application.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 32, tokens 103, triggered by: 0.13\n",
      "\u001b[35mSo many engineers working on the same code base with millions of lines of code, bugs were not that uncommon. It was increasingly hard to ship features or even bug fixes on time. So they looked out for a solution and decided to go with the microservices approach. But then they started to face another set of problems. . . .That's where Kubernetes came in:) See the full video talk by Kunal Parmar, Senior Engineering Manager at Box: https://lnkd.in/etnJTbE\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 33, tokens 119, triggered by: 0.08\n",
      "\u001b[31mI hope you all are #GoT fans here. . . Let me tell you the #Kubernetes story at HBO! The engineers started panicking as they knew the unpredictable traffic for the most anticipated Game of Thrones season seven premiere is going to be HUGE. One of the challenges they found out was the under-utilization of the deployed resources. Node.js code tends only to use a single CPU core. AWS EC2 instances that had excellent networking capabilities tended to be based on dual-core CPUs. As such, HBO was only using 50 percent of the deployed CPU capacity across its deployment.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 34, tokens 113, triggered by: 0.14\n",
      "\u001b[32mThe ability to spin up new instances on EC2 wasn't quite as fast as what HBO needed. HBO also found that in times of peak demand for Game of Thrones, it was also running out of available IP addresses to help deliver the content to viewers. \"We went from not running a single service inside of a container to hosting all of Games of Thrones season 7 with Kubernetes,\" Illya Chekrygin, Senior Staff Engineer at HBO told the KubeCon audience. At last, the HBO chose Kubernetes among other alternatives, basically because of its vibrant and\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 35, tokens 260, triggered by: 0.15\n",
      "\u001b[34mactive community. Credits: KubeCon 2017, eWEEK Italy's biggest traditional bank is embracing #Kubernetes ? A conventional bank running its real business on such a young technology? No way, are you kidding me? Nope, I am not kidding. Italy's banking group, Intesa Sanpaolo, has made this transition. These are banks who still run their ATM networks on 30-year-old mainframe technology, and embracing the hottest trend & tech is nearly unbelievable. Even though ING, the banking and financial corporation, changed the way the banks were seen by upgrading itself with Kubernetes and #DevOps practices very early in the game, there was still a stigma with adopting Kubernetes in the highly regulated and controlled environments like Healthcare, Banks, etc. The bank's engineering team came up with an initiative strategy in 2018 to throw away the old way of thinking and started embracing the technologies like microservices, container architecture, and migrate from monolithic to multi-tier applications. It was transforming itself into a software company, unbelievable. Today the bank runs more than 3,000 applications. Of those, more than 120 are now running in production using the new microservices architecture, including two of the 10 most business-critical for the bank.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 36, tokens 124, triggered by: 0.14\n",
      "\u001b[35mRead the full case here: https://lnkd.in/e_c5fbg How did 'Pokemon Go' able to scale so efficiently? The answer is #Kubernetes . Read the story. . . 500+ million downloads and 20+ million daily active users. That's HUGE. Pokemon Go engineers never thought their user base would increase exponentially surpassing the expectations within a short time. Even the servers couldn't handle this much traffic. The Challenge: The horizontal scaling on one side but Pokemon Go also faced a severe challenge when it came to vertical scaling because of the real-time activity by millions of users worldwide.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 37, tokens 146, triggered by: 0.18\n",
      "\u001b[31mNiantic was not prepared for this. The Solution: The magic of containers. The application logic for the game ran on Google Container Engine (GKE) powered by the open-source Kubernetes project. Niantic chose GKE for its ability to orchestrate their container cluster at planetary-scale, freeing its team to focus on deploying live changes for their players. In this way, Niantic used Google Cloud to turn Pokémon GO into a service for millions of players, continuously adapting and improving. This got them more time to concentrate on building the game's application logic and new features rather than worrying about the scaling part. “Going Viral” is not always easy to predict but you can always have Kubernetes in your tech stack.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 38, tokens 109, triggered by: 0.15\n",
      "\u001b[32mCI/CD with Kubernetes: How can you quickly achieve CI/CD automation with #Kubernetes and roll it out across your organization? Step 1: Develop your microservice using dependencies from registries that are proxied in Artifactory. The resulting App package can be a .war or .jar file. Step 2: Create a Docker Framework using Tomcat and Java-8 on Ubuntu as a base image. Push this image to a Docker registry in Artifactory, where it is also scanned by Xray to assure security and\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 39, tokens 152, triggered by: 0.17\n",
      "\u001b[34mlicense compliance. Step 3: Create the Docker image for the microservice by adding the .war/.jar file to the Docker Framework, and push the image to a Docker registry in Artifactory, where it is scanned by Xray. Step 4: Create a Helm chart for the microservice, and push it to a Helm repository in Artifactory. Step 5: Deploy the microservice from the secure Docker registry to the Kubernetes cluster using the Helm Chart. See the in-depth article: https://lnkd.in/e4Vkc3m Survey and findings: #Kubernetes usage in production is skyrocketing \u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 40, tokens 155, triggered by: 0.28\n",
      "\u001b[35mWhat else? Here are 15 interesting takeaways from the #CNCF annual survey. All information and source credit goes to CNCF - https://lnkd.in/eD9fN2R and Janakiram MSV's article here: https://lnkd.in/eb6GNZS Tips and tricks: #Kubernetes is the ultimate avatar of cloud-native development. Here are some tips and tricks shared by Timothy Josefik on HackerNoon. The whole article is here: https://lnkd.in/eGdmrkR #Kubernetes has become a synonym for #CloudNative tech. More and more companies are trying to use Kubernetes in production, and that's a good move. Take a look at these 10 Kubernetes production checklist. -----------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 41, tokens 198, triggered by: final split\n",
      "\u001b[31mFree resources: Learn a new skill while working from home! Sharing some free #Kubernetes resources for everyone. > Kubernetes the hard way: https://lnkd.in/eu_rkry > Introduction to Kubernetes: https://lnkd.in/ebHEyaY > Learn Kubernetes by Playing the “Game of Pods”: https://lnkd.in/epGmpd9 > Kubernetes by example: https://lnkd.in/eETkYKW > Getting started with Kubernetes: https://lnkd.in/eqD8qWA > Kubernetes hands-on labs: https://lnkd.in/eEgfyDG > Learning path - Kubernetes: https://lnkd.in/ea5H-WH > Fundamentals of Containers, Kubernetes, and Red Hat OpenShift: https://lnkd.in/ea_tfrt > Zero to hero with Kubernetes: https://lnkd.in/eJJRjck That is it:) All credits to Kubernetes for helping companies scale and win big time.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunker.print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Content into Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_strings = []\n",
    "\n",
    "# Iterate through each chunk in the nested list\n",
    "for chunk_list in chunks:  # outer list\n",
    "    for chunk in chunk_list:  # inner list of chunks\n",
    "        # Join the splits of each chunk into a single string and append to the list\n",
    "        concatenated_string = ' '.join(chunk.splits)\n",
    "        concatenated_strings.append(concatenated_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kubernetes For Everyone Kubernetes introduction and features How Kubernetes works? In Kubernetes, there is a master node and multiple worker nodes, each worker node can handle multiple pods. Pods are just a bunch of containers clustered together as a working unit. You can start designing your applications using pods. Once your pods are ready, you can specify pod definitions to the master node, and how many you want to deploy. From this point, Kubernetes is in control. It takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes starts new pods on a functioning worker node. This makes the process of managing the containers easy and simple.',\n",
       " \"It makes it easy to build and add more features and improving the application to attain higher customer satisfaction. Finally, no matter what technology you're invested in, Kubernetes can help you. Image credits: Source: Knoldus Inc What is the Master node and Worker node in #Kubernetes? Explained below, #Containerization is the trend that is taking over the world, allowing firms to run any kind of different applications in a variety of different environments. To keep track of all these containers, to schedule, to manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\",\n",
       " 'exponentially well. Kubernetes is a master-slave type of architecture. It operated with Master node and worker node principles. What exactly they do? Master Node: >The main machine that controls the nodes > Main entry point for all administrative tasks > It handles the orchestration of the worker nodes Worker Node: > It is a worker machine in Kubernetes (used to be known as a minion) > This machine performs the requested tasks. The Master Node controls each Node > Runs containers inside pods > This is where the Docker engine runs and takes care of downloading images and starting containers Know in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes- how-to-get-started/ #Containers are the de-facto deployment format of today. But where does #Kubernetes comes in the play? While tools such as #Docker provide the actual containers, we also need tools to take care of things such as replication, failovers, orchestration, and that is where Kubernetes comes into play. The Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only',\n",
       " \"more reliable, but also much faster, because we’re no longer dealing with VMs. When working with Kubernetes, you have to become accustomed with concepts and namings like pods, services, and replication controllers. If you're not already familiar yet, no worries, there are some excellent resources available to learn Kubernetes and get up to speed. Some key features of Kubernetes that make it unique, > Service Discovery > Health Check Capability > Simplified Monitoring > Self-healing > Secret and configuration management > Horizontal scaling > Storage Management > Networking > Services > ConfigMap and Secret > Logging > Rolling update or rollback > Load balancing What feature do you like the most in Kubernetes? BTW, take a look at these tips, tricks, and lessons for taking containerized apps to k8s:\",\n",
       " 'https://lnkd.in/eZtxx-Z Image credits: TheNewStack #Kubernetes features that we all like:) > Automatic binpacking: This is where Kubernetes helps in automatically placing containers based on their resource requirements, limits, and other constraints, without compromising on availability. > Service discovery and load balancing: In simple words, service discovery is the process of figuring out how to connect to a service. >Self-healing: Restarts the containers that fail, replaces, and reschedules containers when nodes die. > Automated rollouts and rollbacks: With this feature, Kubernetes does progressively roll out changes, and it ensures it doesn’t kill all your instances at the same time. > Secrets and configuration management: Kubernetes has a built-in mechanism of storing configuration values that you would prefer to keep private.',\n",
       " 'Sensitive information such as user name, passwords with encryption, and other credentials can be kept confidentially. > Storage orchestration: Automatically mount the storage system of your choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS, iSCSI, Gluster, Ceph, Cinder, or Flocker. See more in the original article: https://lnkd.in/e8MzdeV #Kubernetes helps in easy automation of container lifecycle management. However, the concept of Kubernetes is quite complex. Here are the top practices of Kubernetes:)',\n",
       " '> Dis-allow root users > Dis-allow privileged containers > Use pod resource limits and requests > Dis-allow new capabilities addition > Dis-allow any changes to the parameters of the kernel > Dis-allow using bin mounts > Use read-only root filesystem > Dis-allow dock socket bind mount access > Dis-allow usage of host ports and networks > Keep smaller base image What else? Know more: https://lnkd.in/ejetevG #Kubernetes Core Features. 1. Container runtime: Kubernetes uses Container Runtime Interface (CRI) to transparently manage your containers without necessarily having to know (or deal with) the runtime used. 2.',\n",
       " 'The Network Plugin: As we discussed earlier, a container orchestration system is responsible (among other things) for managing the network through which containers and services communicate. 3. The Volume Plugin: A volume broadly refers to the storage that will be availed for the pod. 4. Image Registry: Kubernetes must contact an image registry (whether public or private) to be able to pull images and spin out container. 5. Cloud Provider: Kubernetes can be deployed on almost any platform you may think of. 6. Identity Provider: You can use your own identity provider system to authenticate your users to the cluster as long as it uses OpenID connect.',\n",
       " \"Read this amazing article: https://lnkd.in/eySj5aG Kubernetes setup: How much time can you devote to setting up the #Kubernetes ?\\ue012\\ue013\\ue014\\ue015\\ue016\\ue017\\ue000\\ue000 \\ue00d\\ue00e\\ue00f\\ue010\\ue011 That's the question to ask yourself. Because installing and setting up Kubernetes can be daunting. Yes! Kubernetes itself (meaning the plain, open-source version) does not have a built-in installer, nor does it offer much in the way of one-size-fits-all default configurations.\",\n",
       " 'You’ll likelyneed to tweak (or write from scratch) a lot of configuration files before you get your cluster up and running smoothly. Thus, the process of installing and configuring Kubernetes can be a very daunting one that consumes many days of work. Some Kubernetes distributions offer interactive installer scripts that help automate much of the setup process. If you use one of these, setup and installation is easier to accomplish in a day or two. But it’s still by no means a turnkey process. A third option is to run Kubernetes as a managed service in the cloud using a solution like Google Kubernetes Engine, but the downside is, you have less choice and control in determining how to configure your Kubernetes environment. Know more on the facts to consider before selecting Kubernetes: bit.ly/KubernetesSetup #Kubernetes autoscaling.',\n",
       " 'How does it work? Scaling is an essential operational practice that used to be done manually for a long time concerning applications, with the introduction of tools like Kubernetes, the things have changed dramatically in the software industry. In the context of the Kubernetes cluster, there are typically two things you would like to scale as a user, Pods, and Nodes. There are three types of scaling: > HorizontalPodAutoscaler > VerticalPodAutoscaler, and > Cluster Autoscaler. With these techniques, Kubernetes can take intelligent scaling decisions automatically. HorizontalPodAutoscaler refers to increasing the number of Pods serving the application, in',\n",
       " \"response to the present computational needs. VerticalPodAutoscaler involves expanding the resources of the Pods. Cluster Autoscaler (CA) scales your node clusters based on the number of pending pods. It checks to see whether there are any pending pods and increases the size of the cluster so that these pods can be created. Mastering autoscaling needs some patience and persistent efforts to see which technique suits your app's needs by doing trial and error. Continuous learning and experimentation is the key:) More or less #Kubernetes clusters.\",\n",
       " 'How to decide? Kubernetes is devised as a highly available cluster of computers that are connected to work as a single unit for more power and efficiency. The cluster forms the heart of Kubernetes: It can schedule and run containers across a group of machines, be they physical or virtual, on-premises or in the cloud. A Kubernetes cluster is formed out of 2 types of resources: > Master is coordinating the cluster > Nodes are where we run applications Kubernetes is still a bit of sophisticated technology and has a steep learning curve, even after a',\n",
       " 'couple of years working with it, you’ll stillwonder if you got it all under control. But when your company asks you to decide on using and implementing Kubernetes, one question you will have is, deciding on the Kubernetes clusters. My friend Sander has written an amazing article on this, take a look - https://lnkd.in/eSC5vpa Kubernetes security: Keep your clusters updated with the latest #Kubernetes security patches. See how and why. . . Just like any application, Kubernetes is continuously updating new features and security updates. Hence, it is imperative that the underlying nodes and Kubernetes clusters need to be in parallel and up to date as well. The standard “zonal” KubernetesEngine clusters will have only one master node backing them, but you can create “regional” clusters that provide multi-zone feature, highly available masters.',\n",
       " 'One crucial thing to remember here is, while creating a cluster, be sure to select the “regional”option. By using Kubernetes Engine, you can keep your Kubernetes cluster up to date with just a few clicks. It is highly recommended to use Kubernetes Engine regional clusters for the high-availability masters and automatic node upgrades to have a hassle-free upgrade experience. (Source: cloud.google.com ) See my in-depth article on Kubernetes security best practices: https://lnkd.in/eZq9mGs In 2018, a severe vulnerability in #Kubernetes (CVE-2018–1002105) was',\n",
       " \"disclosed. . . This vulnerability allowed an unauthorized and unauthenticated user to gain full admin privileges on a cluster and perform privilege escalation. In one more incident, a security firm RedLock said that hackers accessed one of Tesla’s Amazon cloud accounts, and they used it to run cryptocurrency-mining malware. The initial point of entry for the Tesla cloud breach was an unsecured administrative console for Kubernetes. So many scary stories! Do you know how important is security in Kubernetes? Know here in my in-depth article - https://lnkd.in/ecviJ6c 'Role-Based Access Control' is one of the security best practices in #Kubernetes . Know more about it below.\",\n",
       " '. . RBAC allows Kubernetes architects to specify which types of actions are permitted for a user and what kind of tasks they are going to perform depending on their role in the organization This is how you create roles based on the different kinds of access your users and applications need to various resources, and later assign only the required and minimum permissions for appropriate access to the roles. Minimum or restricting access to only specified and well-identified users who must perform defined actions on a resource is critical in securing your cluster and is one of the security best practices. To tighten the security and ease handling a large number of accounts,',\n",
       " 'RBAC makes use of an intermediate item called binding. Via role binding mechanism, you can create “roles,” which will have a set of capabilities, then assign eachuser one or more roles. For example, some users might just have permission to list pods, and some other users may have permission to get, list, watch, create, update, patch, delete pods. Writing an article on this and will be out soon. [No doubt, It is highly challenging to embrace #CloudNative and#DevOps in regulated industries. As#microservices and container-based infrastructure are enriching how the software is built these days, new challenges with security and compliance appear for regulated firms. Regulated industries imply several challenges > Strong restrictions on secured networks > Fine-grained audit trails > Strong ACLs models > Full lifecycle governance',\n",
       " '> Integration with 3rd parties Here is an example where Artem Semenov from Align Technology is showing us the basic requirements for making #K8S compliant with sensitive data handling regulations and possible technical solutions - https://lnkd.in/g2G-rFX Kubernetes case studies: Delivering Pizza with #Kubernetes ? Domino’s #CloudNative story is mind-blowing. Read:) The company makes splashy headlines with ambitions to deliver pizzas with driverless cars and drones, along with AI and other automation processes. Domino’s currently offers 15 digital ways to order pizza. How does Domino’s deliver so many new solutions, features, and updates, while it’s hot?',\n",
       " 'By cultivating an experimental culture of cloud-native innovation within the company. Applications play a significant role in Domino’s business strategy. Domino’s intends to create new business value and speed their time to market by rewriting core applications to run as microservices. Dominos teams are modernizing these core applications in-house with microservices, but each team uses a different platform. The in-house teams chose a comprehensive, production-grade Kubernetes distribution platform with enterprise security features and full lifecycle management support and with Kubernetes, Domino’s is evaluating the feasibility and level of effort to convert current systems and processes to a container- based architecture.',\n",
       " 'Read the full story: https://lnkd.in/eZzagGH Kubernetes best practices for taking your containers all the way to production: https://lnkd.in/eZtxx- Z How did Airbnb enable 1,000+ engineers with #Kubernetes ? This is the talk summary of Melanie Cebula at Qcon London. About the way her team wraps Kubernetes into easy-to-consume internal services for its development teams. Instead of creating a set of dreaded YAML files per environment, development teams need only provide their project-specific, service-focused inputs and then run the internal service kube-gen (alias k gen). This simple command takes care of generating all the required YAML files, ensuring their correctness, and finally applying them in the corresponding Kubernetes cluster(s).',\n",
       " \"The infrastructure team at Airbnb is saving hundreds, if not thousands, of hours for 1,000+ engineers who can now use a much simpler abstraction that has been adapted to their needs, with a user experience that's familiar to them. Know more about this story at: https://lnkd.in/egDqpHE The figure above shows the kube-gen wrapper generates the needed configuration files per environment at Airbnb. Source: Melanie Cebula, Airbnb. A 50-year-old audio company using #Kubernetes ? That's insane. Read:) It supports rapid development for millions of #IoT products with Kubernetes. How? Bose has been a big player in helping IoT devices and audio enabling systems for several years. Bose engineering leadership team always wanted to move to a microservices architecture. When the demand started growing, they had to look for a solution that can help their engineering platform team to deploy services to production quickly without any hassle. For this, they evaluated and found many alternative platforms but finally chose Kubernetes due to its scaled IoT platform-as- a-service running on AWS and vibrant community aspect. They launched a revised platform along with Prometheus, An open-source monitoring system to serve more than 3 million connected IoT devices. Today, Bose has over 1,800 namespaces and 340 worker nodes in one of its live production clusters. Bose has more than 100 engineers working on this platform already, this platform is helping them make 30,000 nonproduction deployments every\",\n",
       " \"year. Read the original story: https://lnkd.in/eJgBRHN Also, take a look at this video on CI/CD enablement for connected device products with OTA capabilities: http://bit.ly/IoTCICD Amadeus's lift and shift to #Kubernetes . An inspiring #CloudNative story for you. Read. . . . . Amadeus had two choices: Either pour more concrete and extend the data center or move the workload to the cloud & this made them go with Google Cloud. So within 18 months, Amadeus had lifted and shifted one of their most critical application 'Master Pricer' to the Google Cloud Platform. Now you know, the next step for them was to move to Kubernetes since it made more sense with Google Cloud Platform. The aim is, they wanted to go faster with Kubernetes, and the challenge was to add a disciplinary policy of learning Kubernetes across the team. So, the team at Amadeus started learning how to operate Kubernetes and how to monitor it, do alerting. During the migration, Amadeus had engineers from both Google and Red Hat on site to help them get to grips with OpenShift and the container orchestration technology Kubernetes. The overall goal for Amadeus is to move all production workloads to run on a single operating model with Kubernetes.\",\n",
       " \"The company now feels it made the right bet. Credits: https://lnkd.in/gS3n_vy http://bit.ly/AmadeusGCP #Kubernetes has helped Adidas to deploy faster, safer, with more quality and scale quickly. Read further. . . Adidas understood the importance of Kubernetes over VMs, and now their tech stack is wholly powered by Kubernetes. Before creating a VM would take days or even weeks that would impact the developers' productivity and the business overall. Kubernetes helped Adidas to get rid of the overhead that comes with a VM-based infrastructure. Deployments that used to take four to five days can now be deployed four to five times a day with the help of Kubernetes. Currently, Adidas has over 4,000 pods running on Kubernetes, achieving the velocity it needs to develop applications faster than ever. Their lead infrastructure engineers say that, it is easy to set up and configure the new tool, but the problem comes in scaling. They also stressed on the point that training is essential for engineers working on the platform. Source credits: TechGenix #Kubernetes is sexy because it attracts modern engineers that care about #CloudNative technologies.\\ue008 \\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\",\n",
       " \"Read how News UK utilized the power of Kubernetes to save itself in the cloud-native world. The critical goal for News UK was to be better able to scale up its environment around breaking news events & unpredictable reader volumes. They thought if VMs can help them, but soon they realized that VMs take long to spin up and when there is a spike of traffic, it is not fast enough to bring new capacity into the AutoScalingGroup (that's what Marcin Cuber, a former cloud DevOps engineer at News UK has to say) They adopted Docker and Kubernetes. Docker containers running in Kubernetes are smaller and lightweight, and they can easily help to scale up or scale down as required. Cuber also had some advice for any organization looking to adopt Docker and Kubernetes. > make your Docker images as small as possible and to focus on running stateless applications with Kubernetes > run health checks for your applications and to use YAML to deploy anything News UK also wanted to cut cloud costs, so they paired EKS clusters with AWS spot instances, and they also used AWS Lambda to make this work efficiently. The full case study: https://lnkd.in/e4iAq2r A banking app's must-read story of running #Kubernetes in production. A journey that affirms you don't have to be too big to use Kubernetes. They started their #CloudNative journey by splitting the massive monolith application into smaller microservices.\",\n",
       " \"To spin up these microservices, they used Ansible, Terraform, and Jenkins and to deploy these microservices as a whole unit (as shown in the image). Then they suddenly started to experience some of the scaling issues with Microservices. So, they didn't get any of the microservices benefits. Hence they started looking for ways to get out of this complexity by shifting their focus from machine-oriented to application-oriented architecture. They chose Kubernetes as the abstraction layer along with AWS, not worrying about where the containers are running, and this is how they were able to manage microservices and unlocked the velocity of microservices. They also chose Kubernetes from a security perspective and to specify how the applications should run. Now they run around 80+ microservices now in production with the help of Kubernetes:) Watch and learn how they did it in this video 'Running Kubernetes in production at Lunar Way by\",\n",
       " \"Kasper Nissen.' - https://lnkd.in/eU9s3JX Why did eBay choose #Kubernetes ? Daily, eBay handles 300 billion data queries & a massive amount of data that’s above 500 petabytes. eBay has to move massive amounts of data & manage the traffic, keeping in mind a smooth user experience while still ensuring a secure, stable environment that’s flexible enough to encourage innovation. In the fall of 2018, the company announced they were in the midst of a three-year plan they called “re-platforming.” eBay's 90% of cloud technology was dependent on OpenStack, and they are in the move to ditch OpenStack altogether. eBay is “re-platforming, itself with Kubernetes, Docker, & Apache Kafka, a stream processing platform that increases data handling and decreases latency.\",\n",
       " \"The goal is to improve the user experience and to promote productivity with their engineers and programmers & completely revamp its data center infrastructure. The other activities in this re-platforming include designing their own custom servers and rolling out a new, decentralized strategy for their data centers. Like Facebook & Microsoft, eBay is relying on open-sourcing to design their custom servers. Such an inspiring case study. Bloomberg is one of the first companies to adopt #Kubernetes . They used Kubernetes into production in 2017. The aim was to bring up new applications and services to users as fast as possible and free up developers from operational tasks. After evaluating many offerings from different firms, they selected Kubernetes as they thought it aligned exactly with what they were trying to solve. One of the key aims at Bloomberg was to make better use of existing hardware investments using different features of Kubernetes. As a result, they were able to very efficiently use the hardware to the point where they could get close to 90 to 95 percent utilization rates (as per Andrey Rybka, head of the compute infrastructure team at Bloomberg) Nothing great comes easy; Kubernetes makes many things simpler only if you know how to use it. As the developers initially found it challenging to use, the teams had many training programs around Kubernetes at Bloomberg. Shopify's #Kubernetes journey is just minded blowing:) Shopify was one of the pioneers in large-scale users of #Docker in production.\",\n",
       " 'They ran 100% of their production traffic in hundreds of containers. Shopify engineering team saw the real value of containerization and also aspired to introduce a real orchestration layer. They started looking at orchestration solutions, and the technology behind Kubernetes fascinated them. It all started in 2016, where all the engineers were happy running services everywhere with a simple stack that included Chef, Docker, AWS, and Heroku. But just like any other company that is in the growth phase, the Shopify encountered some challenges when this Canadian e-commerce company saw 80k+ requests per second during peak demand. Wohooo:) Many processes were not scalable, and they needed a quick solution. The Shopify team recognized that they needed to increase their focus on tested infrastructure and automation that works as',\n",
       " \"expected, every time. The Shopify engineering team believed in three principles: providing a 'paved road, 'hide complexity' and 'self-serve.' Read this fascinating story here: https://lnkd.in/eN34vAm All credits to Niko Kurtti, QCon & InfoQ. Box’s #Kubernetes journey is one of the finest #CloudNative inspirations. Read… A few years ago at Box, it was taking up to six months to build a new #microservice . Fast forward to today, it takes only a couple of days. How did they manage to speed up? Two key factors made it possible,\",\n",
       " '1. Kubernetes technology 2. DevOps practices Founded in 2005, Box was a monolithic PHP application and had grown over time to millions of lines of code. The monolithic nature of their application led to them basically building very tightly coupled designs, and this tight coupling was coming in their way. It was resulting in them not being able to innovate as quickly as they wanted to. Bugs in one part of their application would require them to roll back the entire application.',\n",
       " \"So many engineers working on the same code base with millions of lines of code, bugs were not that uncommon. It was increasingly hard to ship features or even bug fixes on time. So they looked out for a solution and decided to go with the microservices approach. But then they started to face another set of problems. . . .That's where Kubernetes came in:) See the full video talk by Kunal Parmar, Senior Engineering Manager at Box: https://lnkd.in/etnJTbE\",\n",
       " 'I hope you all are #GoT fans here. . . Let me tell you the #Kubernetes story at HBO! The engineers started panicking as they knew the unpredictable traffic for the most anticipated Game of Thrones season seven premiere is going to be HUGE. One of the challenges they found out was the under-utilization of the deployed resources. Node.js code tends only to use a single CPU core. AWS EC2 instances that had excellent networking capabilities tended to be based on dual-core CPUs. As such, HBO was only using 50 percent of the deployed CPU capacity across its deployment.',\n",
       " 'The ability to spin up new instances on EC2 wasn\\'t quite as fast as what HBO needed. HBO also found that in times of peak demand for Game of Thrones, it was also running out of available IP addresses to help deliver the content to viewers. \"We went from not running a single service inside of a container to hosting all of Games of Thrones season 7 with Kubernetes,\" Illya Chekrygin, Senior Staff Engineer at HBO told the KubeCon audience. At last, the HBO chose Kubernetes among other alternatives, basically because of its vibrant and',\n",
       " \"active community. Credits: KubeCon 2017, eWEEK Italy's biggest traditional bank is embracing #Kubernetes ? A conventional bank running its real business on such a young technology? No way, are you kidding me? Nope, I am not kidding. Italy's banking group, Intesa Sanpaolo, has made this transition. These are banks who still run their ATM networks on 30-year-old mainframe technology, and embracing the hottest trend & tech is nearly unbelievable. Even though ING, the banking and financial corporation, changed the way the banks were seen by upgrading itself with Kubernetes and #DevOps practices very early in the game, there was still a stigma with adopting Kubernetes in the highly regulated and controlled environments like Healthcare, Banks, etc. The bank's engineering team came up with an initiative strategy in 2018 to throw away the old way of thinking and started embracing the technologies like microservices, container architecture, and migrate from monolithic to multi-tier applications. It was transforming itself into a software company, unbelievable. Today the bank runs more than 3,000 applications. Of those, more than 120 are now running in production using the new microservices architecture, including two of the 10 most business-critical for the bank.\",\n",
       " \"Read the full case here: https://lnkd.in/e_c5fbg How did 'Pokemon Go' able to scale so efficiently? The answer is #Kubernetes . Read the story. . . 500+ million downloads and 20+ million daily active users. That's HUGE. Pokemon Go engineers never thought their user base would increase exponentially surpassing the expectations within a short time. Even the servers couldn't handle this much traffic. The Challenge: The horizontal scaling on one side but Pokemon Go also faced a severe challenge when it came to vertical scaling because of the real-time activity by millions of users worldwide.\",\n",
       " \"Niantic was not prepared for this. The Solution: The magic of containers. The application logic for the game ran on Google Container Engine (GKE) powered by the open-source Kubernetes project. Niantic chose GKE for its ability to orchestrate their container cluster at planetary-scale, freeing its team to focus on deploying live changes for their players. In this way, Niantic used Google Cloud to turn Pokémon GO into a service for millions of players, continuously adapting and improving. This got them more time to concentrate on building the game's application logic and new features rather than worrying about the scaling part. “Going Viral” is not always easy to predict but you can always have Kubernetes in your tech stack.\",\n",
       " 'CI/CD with Kubernetes: How can you quickly achieve CI/CD automation with #Kubernetes and roll it out across your organization? Step 1: Develop your microservice using dependencies from registries that are proxied in Artifactory. The resulting App package can be a .war or .jar file. Step 2: Create a Docker Framework using Tomcat and Java-8 on Ubuntu as a base image. Push this image to a Docker registry in Artifactory, where it is also scanned by Xray to assure security and',\n",
       " 'license compliance. Step 3: Create the Docker image for the microservice by adding the .war/.jar file to the Docker Framework, and push the image to a Docker registry in Artifactory, where it is scanned by Xray. Step 4: Create a Helm chart for the microservice, and push it to a Helm repository in Artifactory. Step 5: Deploy the microservice from the secure Docker registry to the Kubernetes cluster using the Helm Chart. See the in-depth article: https://lnkd.in/e4Vkc3m Survey and findings: #Kubernetes usage in production is skyrocketing\\ue018 \\ue019\\ue01a\\ue01b\\ue01c\\ue01d\\ue01e\\ue01f',\n",
       " \"What else? Here are 15 interesting takeaways from the #CNCF annual survey. All information and source credit goes to CNCF - https://lnkd.in/eD9fN2R and Janakiram MSV's article here: https://lnkd.in/eb6GNZS Tips and tricks: #Kubernetes is the ultimate avatar of cloud-native development. Here are some tips and tricks shared by Timothy Josefik on HackerNoon. The whole article is here: https://lnkd.in/eGdmrkR #Kubernetes has become a synonym for #CloudNative tech. More and more companies are trying to use Kubernetes in production, and that's a good move. Take a look at these 10 Kubernetes production checklist. -----------------------------------------------------------------------------------------------------------------------------------------------------------------\",\n",
       " 'Free resources: Learn a new skill while working from home! Sharing some free #Kubernetes resources for everyone. > Kubernetes the hard way: https://lnkd.in/eu_rkry > Introduction to Kubernetes: https://lnkd.in/ebHEyaY > Learn Kubernetes by Playing the “Game of Pods”: https://lnkd.in/epGmpd9 > Kubernetes by example: https://lnkd.in/eETkYKW > Getting started with Kubernetes: https://lnkd.in/eqD8qWA > Kubernetes hands-on labs: https://lnkd.in/eEgfyDG > Learning path - Kubernetes: https://lnkd.in/ea5H-WH > Fundamentals of Containers, Kubernetes, and Red Hat OpenShift: https://lnkd.in/ea_tfrt > Zero to hero with Kubernetes: https://lnkd.in/eJJRjck That is it:) All credits to Kubernetes for helping companies scale and win big time.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kubernetes For Everyone Kubernetes introduction and features How Kubernetes works? In Kubernetes, there is a master node and multiple worker nodes, each worker node can handle multiple pods. Pods are just a bunch of containers clustered together as a working unit. You can start designing your applications using pods. Once your pods are ready, you can specify pod definitions to the master node, and how many you want to deploy. From this point, Kubernetes is in control. It takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes starts new pods on a functioning worker node. This makes the process of managing the containers easy and simple.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  41\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks: \",len(concatenated_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder(concatenated_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.7863475968747669\n"
     ]
    }
   ],
   "source": [
    "# The Cosine similarity between two embedding vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(f\"Cosine similarity: {similarity[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_shape(lst):\n",
    "    shape = [len(lst)]\n",
    "    if isinstance(lst[0], list):\n",
    "        shape.append(len(lst[0]))\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 384]\n"
     ]
    }
   ],
   "source": [
    "print(list_shape(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np = np.array(embeddings).astype('float32')\n",
    "# Building The FAISS index using Euclidean distance\n",
    "index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
    "# Adding the embeddings to the index\n",
    "index.add(embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 41\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of vectors in the index: {index.ntotal}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_np[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [[0 2 1]]\n",
      "Distances to nearest neighbors: [[0.         0.3200307  0.42730483]]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "# Testing\n",
    "# Searching for the k-nearest neighbors of the first embedding embeddings_np[0:1]\n",
    "distances, indices = index.search(embeddings_np[0:1], k)\n",
    "\n",
    "print(f\"Indices of nearest neighbors: {indices}\")\n",
    "print(f\"Distances to nearest neighbors: {distances}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kubernetes For Everyone Kubernetes introduction and features How Kubernetes works? In Kubernetes, there is a master node and multiple worker nodes, each worker node can handle multiple pods. Pods are just a bunch of containers clustered together as a working unit. You can start designing your applications using pods. Once your pods are ready, you can specify pod definitions to the master node, and how many you want to deploy. From this point, Kubernetes is in control. It takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes starts new pods on a functioning worker node. This makes the process of managing the containers easy and simple.',\n",
       " \"It makes it easy to build and add more features and improving the application to attain higher customer satisfaction. Finally, no matter what technology you're invested in, Kubernetes can help you. Image credits: Source: Knoldus Inc What is the Master node and Worker node in #Kubernetes? Explained below, #Containerization is the trend that is taking over the world, allowing firms to run any kind of different applications in a variety of different environments. To keep track of all these containers, to schedule, to manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\",\n",
       " 'exponentially well. Kubernetes is a master-slave type of architecture. It operated with Master node and worker node principles. What exactly they do? Master Node: >The main machine that controls the nodes > Main entry point for all administrative tasks > It handles the orchestration of the worker nodes Worker Node: > It is a worker machine in Kubernetes (used to be known as a minion) > This machine performs the requested tasks. The Master Node controls each Node > Runs containers inside pods > This is where the Docker engine runs and takes care of downloading images and starting containers Know in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes- how-to-get-started/ #Containers are the de-facto deployment format of today. But where does #Kubernetes comes in the play? While tools such as #Docker provide the actual containers, we also need tools to take care of things such as replication, failovers, orchestration, and that is where Kubernetes comes into play. The Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only',\n",
       " \"more reliable, but also much faster, because we’re no longer dealing with VMs. When working with Kubernetes, you have to become accustomed with concepts and namings like pods, services, and replication controllers. If you're not already familiar yet, no worries, there are some excellent resources available to learn Kubernetes and get up to speed. Some key features of Kubernetes that make it unique, > Service Discovery > Health Check Capability > Simplified Monitoring > Self-healing > Secret and configuration management > Horizontal scaling > Storage Management > Networking > Services > ConfigMap and Secret > Logging > Rolling update or rollback > Load balancing What feature do you like the most in Kubernetes? BTW, take a look at these tips, tricks, and lessons for taking containerized apps to k8s:\",\n",
       " 'https://lnkd.in/eZtxx-Z Image credits: TheNewStack #Kubernetes features that we all like:) > Automatic binpacking: This is where Kubernetes helps in automatically placing containers based on their resource requirements, limits, and other constraints, without compromising on availability. > Service discovery and load balancing: In simple words, service discovery is the process of figuring out how to connect to a service. >Self-healing: Restarts the containers that fail, replaces, and reschedules containers when nodes die. > Automated rollouts and rollbacks: With this feature, Kubernetes does progressively roll out changes, and it ensures it doesn’t kill all your instances at the same time. > Secrets and configuration management: Kubernetes has a built-in mechanism of storing configuration values that you would prefer to keep private.',\n",
       " 'Sensitive information such as user name, passwords with encryption, and other credentials can be kept confidentially. > Storage orchestration: Automatically mount the storage system of your choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS, iSCSI, Gluster, Ceph, Cinder, or Flocker. See more in the original article: https://lnkd.in/e8MzdeV #Kubernetes helps in easy automation of container lifecycle management. However, the concept of Kubernetes is quite complex. Here are the top practices of Kubernetes:)',\n",
       " '> Dis-allow root users > Dis-allow privileged containers > Use pod resource limits and requests > Dis-allow new capabilities addition > Dis-allow any changes to the parameters of the kernel > Dis-allow using bin mounts > Use read-only root filesystem > Dis-allow dock socket bind mount access > Dis-allow usage of host ports and networks > Keep smaller base image What else? Know more: https://lnkd.in/ejetevG #Kubernetes Core Features. 1. Container runtime: Kubernetes uses Container Runtime Interface (CRI) to transparently manage your containers without necessarily having to know (or deal with) the runtime used. 2.',\n",
       " 'The Network Plugin: As we discussed earlier, a container orchestration system is responsible (among other things) for managing the network through which containers and services communicate. 3. The Volume Plugin: A volume broadly refers to the storage that will be availed for the pod. 4. Image Registry: Kubernetes must contact an image registry (whether public or private) to be able to pull images and spin out container. 5. Cloud Provider: Kubernetes can be deployed on almost any platform you may think of. 6. Identity Provider: You can use your own identity provider system to authenticate your users to the cluster as long as it uses OpenID connect.',\n",
       " \"Read this amazing article: https://lnkd.in/eySj5aG Kubernetes setup: How much time can you devote to setting up the #Kubernetes ?\\ue012\\ue013\\ue014\\ue015\\ue016\\ue017\\ue000\\ue000 \\ue00d\\ue00e\\ue00f\\ue010\\ue011 That's the question to ask yourself. Because installing and setting up Kubernetes can be daunting. Yes! Kubernetes itself (meaning the plain, open-source version) does not have a built-in installer, nor does it offer much in the way of one-size-fits-all default configurations.\",\n",
       " 'You’ll likelyneed to tweak (or write from scratch) a lot of configuration files before you get your cluster up and running smoothly. Thus, the process of installing and configuring Kubernetes can be a very daunting one that consumes many days of work. Some Kubernetes distributions offer interactive installer scripts that help automate much of the setup process. If you use one of these, setup and installation is easier to accomplish in a day or two. But it’s still by no means a turnkey process. A third option is to run Kubernetes as a managed service in the cloud using a solution like Google Kubernetes Engine, but the downside is, you have less choice and control in determining how to configure your Kubernetes environment. Know more on the facts to consider before selecting Kubernetes: bit.ly/KubernetesSetup #Kubernetes autoscaling.',\n",
       " 'How does it work? Scaling is an essential operational practice that used to be done manually for a long time concerning applications, with the introduction of tools like Kubernetes, the things have changed dramatically in the software industry. In the context of the Kubernetes cluster, there are typically two things you would like to scale as a user, Pods, and Nodes. There are three types of scaling: > HorizontalPodAutoscaler > VerticalPodAutoscaler, and > Cluster Autoscaler. With these techniques, Kubernetes can take intelligent scaling decisions automatically. HorizontalPodAutoscaler refers to increasing the number of Pods serving the application, in',\n",
       " \"response to the present computational needs. VerticalPodAutoscaler involves expanding the resources of the Pods. Cluster Autoscaler (CA) scales your node clusters based on the number of pending pods. It checks to see whether there are any pending pods and increases the size of the cluster so that these pods can be created. Mastering autoscaling needs some patience and persistent efforts to see which technique suits your app's needs by doing trial and error. Continuous learning and experimentation is the key:) More or less #Kubernetes clusters.\",\n",
       " 'How to decide? Kubernetes is devised as a highly available cluster of computers that are connected to work as a single unit for more power and efficiency. The cluster forms the heart of Kubernetes: It can schedule and run containers across a group of machines, be they physical or virtual, on-premises or in the cloud. A Kubernetes cluster is formed out of 2 types of resources: > Master is coordinating the cluster > Nodes are where we run applications Kubernetes is still a bit of sophisticated technology and has a steep learning curve, even after a',\n",
       " 'couple of years working with it, you’ll stillwonder if you got it all under control. But when your company asks you to decide on using and implementing Kubernetes, one question you will have is, deciding on the Kubernetes clusters. My friend Sander has written an amazing article on this, take a look - https://lnkd.in/eSC5vpa Kubernetes security: Keep your clusters updated with the latest #Kubernetes security patches. See how and why. . . Just like any application, Kubernetes is continuously updating new features and security updates. Hence, it is imperative that the underlying nodes and Kubernetes clusters need to be in parallel and up to date as well. The standard “zonal” KubernetesEngine clusters will have only one master node backing them, but you can create “regional” clusters that provide multi-zone feature, highly available masters.',\n",
       " 'One crucial thing to remember here is, while creating a cluster, be sure to select the “regional”option. By using Kubernetes Engine, you can keep your Kubernetes cluster up to date with just a few clicks. It is highly recommended to use Kubernetes Engine regional clusters for the high-availability masters and automatic node upgrades to have a hassle-free upgrade experience. (Source: cloud.google.com ) See my in-depth article on Kubernetes security best practices: https://lnkd.in/eZq9mGs In 2018, a severe vulnerability in #Kubernetes (CVE-2018–1002105) was',\n",
       " \"disclosed. . . This vulnerability allowed an unauthorized and unauthenticated user to gain full admin privileges on a cluster and perform privilege escalation. In one more incident, a security firm RedLock said that hackers accessed one of Tesla’s Amazon cloud accounts, and they used it to run cryptocurrency-mining malware. The initial point of entry for the Tesla cloud breach was an unsecured administrative console for Kubernetes. So many scary stories! Do you know how important is security in Kubernetes? Know here in my in-depth article - https://lnkd.in/ecviJ6c 'Role-Based Access Control' is one of the security best practices in #Kubernetes . Know more about it below.\",\n",
       " '. . RBAC allows Kubernetes architects to specify which types of actions are permitted for a user and what kind of tasks they are going to perform depending on their role in the organization This is how you create roles based on the different kinds of access your users and applications need to various resources, and later assign only the required and minimum permissions for appropriate access to the roles. Minimum or restricting access to only specified and well-identified users who must perform defined actions on a resource is critical in securing your cluster and is one of the security best practices. To tighten the security and ease handling a large number of accounts,',\n",
       " 'RBAC makes use of an intermediate item called binding. Via role binding mechanism, you can create “roles,” which will have a set of capabilities, then assign eachuser one or more roles. For example, some users might just have permission to list pods, and some other users may have permission to get, list, watch, create, update, patch, delete pods. Writing an article on this and will be out soon. [No doubt, It is highly challenging to embrace #CloudNative and#DevOps in regulated industries. As#microservices and container-based infrastructure are enriching how the software is built these days, new challenges with security and compliance appear for regulated firms. Regulated industries imply several challenges > Strong restrictions on secured networks > Fine-grained audit trails > Strong ACLs models > Full lifecycle governance',\n",
       " '> Integration with 3rd parties Here is an example where Artem Semenov from Align Technology is showing us the basic requirements for making #K8S compliant with sensitive data handling regulations and possible technical solutions - https://lnkd.in/g2G-rFX Kubernetes case studies: Delivering Pizza with #Kubernetes ? Domino’s #CloudNative story is mind-blowing. Read:) The company makes splashy headlines with ambitions to deliver pizzas with driverless cars and drones, along with AI and other automation processes. Domino’s currently offers 15 digital ways to order pizza. How does Domino’s deliver so many new solutions, features, and updates, while it’s hot?',\n",
       " 'By cultivating an experimental culture of cloud-native innovation within the company. Applications play a significant role in Domino’s business strategy. Domino’s intends to create new business value and speed their time to market by rewriting core applications to run as microservices. Dominos teams are modernizing these core applications in-house with microservices, but each team uses a different platform. The in-house teams chose a comprehensive, production-grade Kubernetes distribution platform with enterprise security features and full lifecycle management support and with Kubernetes, Domino’s is evaluating the feasibility and level of effort to convert current systems and processes to a container- based architecture.',\n",
       " 'Read the full story: https://lnkd.in/eZzagGH Kubernetes best practices for taking your containers all the way to production: https://lnkd.in/eZtxx- Z How did Airbnb enable 1,000+ engineers with #Kubernetes ? This is the talk summary of Melanie Cebula at Qcon London. About the way her team wraps Kubernetes into easy-to-consume internal services for its development teams. Instead of creating a set of dreaded YAML files per environment, development teams need only provide their project-specific, service-focused inputs and then run the internal service kube-gen (alias k gen). This simple command takes care of generating all the required YAML files, ensuring their correctness, and finally applying them in the corresponding Kubernetes cluster(s).',\n",
       " \"The infrastructure team at Airbnb is saving hundreds, if not thousands, of hours for 1,000+ engineers who can now use a much simpler abstraction that has been adapted to their needs, with a user experience that's familiar to them. Know more about this story at: https://lnkd.in/egDqpHE The figure above shows the kube-gen wrapper generates the needed configuration files per environment at Airbnb. Source: Melanie Cebula, Airbnb. A 50-year-old audio company using #Kubernetes ? That's insane. Read:) It supports rapid development for millions of #IoT products with Kubernetes. How? Bose has been a big player in helping IoT devices and audio enabling systems for several years. Bose engineering leadership team always wanted to move to a microservices architecture. When the demand started growing, they had to look for a solution that can help their engineering platform team to deploy services to production quickly without any hassle. For this, they evaluated and found many alternative platforms but finally chose Kubernetes due to its scaled IoT platform-as- a-service running on AWS and vibrant community aspect. They launched a revised platform along with Prometheus, An open-source monitoring system to serve more than 3 million connected IoT devices. Today, Bose has over 1,800 namespaces and 340 worker nodes in one of its live production clusters. Bose has more than 100 engineers working on this platform already, this platform is helping them make 30,000 nonproduction deployments every\",\n",
       " \"year. Read the original story: https://lnkd.in/eJgBRHN Also, take a look at this video on CI/CD enablement for connected device products with OTA capabilities: http://bit.ly/IoTCICD Amadeus's lift and shift to #Kubernetes . An inspiring #CloudNative story for you. Read. . . . . Amadeus had two choices: Either pour more concrete and extend the data center or move the workload to the cloud & this made them go with Google Cloud. So within 18 months, Amadeus had lifted and shifted one of their most critical application 'Master Pricer' to the Google Cloud Platform. Now you know, the next step for them was to move to Kubernetes since it made more sense with Google Cloud Platform. The aim is, they wanted to go faster with Kubernetes, and the challenge was to add a disciplinary policy of learning Kubernetes across the team. So, the team at Amadeus started learning how to operate Kubernetes and how to monitor it, do alerting. During the migration, Amadeus had engineers from both Google and Red Hat on site to help them get to grips with OpenShift and the container orchestration technology Kubernetes. The overall goal for Amadeus is to move all production workloads to run on a single operating model with Kubernetes.\",\n",
       " \"The company now feels it made the right bet. Credits: https://lnkd.in/gS3n_vy http://bit.ly/AmadeusGCP #Kubernetes has helped Adidas to deploy faster, safer, with more quality and scale quickly. Read further. . . Adidas understood the importance of Kubernetes over VMs, and now their tech stack is wholly powered by Kubernetes. Before creating a VM would take days or even weeks that would impact the developers' productivity and the business overall. Kubernetes helped Adidas to get rid of the overhead that comes with a VM-based infrastructure. Deployments that used to take four to five days can now be deployed four to five times a day with the help of Kubernetes. Currently, Adidas has over 4,000 pods running on Kubernetes, achieving the velocity it needs to develop applications faster than ever. Their lead infrastructure engineers say that, it is easy to set up and configure the new tool, but the problem comes in scaling. They also stressed on the point that training is essential for engineers working on the platform. Source credits: TechGenix #Kubernetes is sexy because it attracts modern engineers that care about #CloudNative technologies.\\ue008 \\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\\ue008\\ue009\\ue00a\\ue00b\\ue00c\",\n",
       " \"Read how News UK utilized the power of Kubernetes to save itself in the cloud-native world. The critical goal for News UK was to be better able to scale up its environment around breaking news events & unpredictable reader volumes. They thought if VMs can help them, but soon they realized that VMs take long to spin up and when there is a spike of traffic, it is not fast enough to bring new capacity into the AutoScalingGroup (that's what Marcin Cuber, a former cloud DevOps engineer at News UK has to say) They adopted Docker and Kubernetes. Docker containers running in Kubernetes are smaller and lightweight, and they can easily help to scale up or scale down as required. Cuber also had some advice for any organization looking to adopt Docker and Kubernetes. > make your Docker images as small as possible and to focus on running stateless applications with Kubernetes > run health checks for your applications and to use YAML to deploy anything News UK also wanted to cut cloud costs, so they paired EKS clusters with AWS spot instances, and they also used AWS Lambda to make this work efficiently. The full case study: https://lnkd.in/e4iAq2r A banking app's must-read story of running #Kubernetes in production. A journey that affirms you don't have to be too big to use Kubernetes. They started their #CloudNative journey by splitting the massive monolith application into smaller microservices.\",\n",
       " \"To spin up these microservices, they used Ansible, Terraform, and Jenkins and to deploy these microservices as a whole unit (as shown in the image). Then they suddenly started to experience some of the scaling issues with Microservices. So, they didn't get any of the microservices benefits. Hence they started looking for ways to get out of this complexity by shifting their focus from machine-oriented to application-oriented architecture. They chose Kubernetes as the abstraction layer along with AWS, not worrying about where the containers are running, and this is how they were able to manage microservices and unlocked the velocity of microservices. They also chose Kubernetes from a security perspective and to specify how the applications should run. Now they run around 80+ microservices now in production with the help of Kubernetes:) Watch and learn how they did it in this video 'Running Kubernetes in production at Lunar Way by\",\n",
       " \"Kasper Nissen.' - https://lnkd.in/eU9s3JX Why did eBay choose #Kubernetes ? Daily, eBay handles 300 billion data queries & a massive amount of data that’s above 500 petabytes. eBay has to move massive amounts of data & manage the traffic, keeping in mind a smooth user experience while still ensuring a secure, stable environment that’s flexible enough to encourage innovation. In the fall of 2018, the company announced they were in the midst of a three-year plan they called “re-platforming.” eBay's 90% of cloud technology was dependent on OpenStack, and they are in the move to ditch OpenStack altogether. eBay is “re-platforming, itself with Kubernetes, Docker, & Apache Kafka, a stream processing platform that increases data handling and decreases latency.\",\n",
       " \"The goal is to improve the user experience and to promote productivity with their engineers and programmers & completely revamp its data center infrastructure. The other activities in this re-platforming include designing their own custom servers and rolling out a new, decentralized strategy for their data centers. Like Facebook & Microsoft, eBay is relying on open-sourcing to design their custom servers. Such an inspiring case study. Bloomberg is one of the first companies to adopt #Kubernetes . They used Kubernetes into production in 2017. The aim was to bring up new applications and services to users as fast as possible and free up developers from operational tasks. After evaluating many offerings from different firms, they selected Kubernetes as they thought it aligned exactly with what they were trying to solve. One of the key aims at Bloomberg was to make better use of existing hardware investments using different features of Kubernetes. As a result, they were able to very efficiently use the hardware to the point where they could get close to 90 to 95 percent utilization rates (as per Andrey Rybka, head of the compute infrastructure team at Bloomberg) Nothing great comes easy; Kubernetes makes many things simpler only if you know how to use it. As the developers initially found it challenging to use, the teams had many training programs around Kubernetes at Bloomberg. Shopify's #Kubernetes journey is just minded blowing:) Shopify was one of the pioneers in large-scale users of #Docker in production.\",\n",
       " 'They ran 100% of their production traffic in hundreds of containers. Shopify engineering team saw the real value of containerization and also aspired to introduce a real orchestration layer. They started looking at orchestration solutions, and the technology behind Kubernetes fascinated them. It all started in 2016, where all the engineers were happy running services everywhere with a simple stack that included Chef, Docker, AWS, and Heroku. But just like any other company that is in the growth phase, the Shopify encountered some challenges when this Canadian e-commerce company saw 80k+ requests per second during peak demand. Wohooo:) Many processes were not scalable, and they needed a quick solution. The Shopify team recognized that they needed to increase their focus on tested infrastructure and automation that works as',\n",
       " \"expected, every time. The Shopify engineering team believed in three principles: providing a 'paved road, 'hide complexity' and 'self-serve.' Read this fascinating story here: https://lnkd.in/eN34vAm All credits to Niko Kurtti, QCon & InfoQ. Box’s #Kubernetes journey is one of the finest #CloudNative inspirations. Read… A few years ago at Box, it was taking up to six months to build a new #microservice . Fast forward to today, it takes only a couple of days. How did they manage to speed up? Two key factors made it possible,\",\n",
       " '1. Kubernetes technology 2. DevOps practices Founded in 2005, Box was a monolithic PHP application and had grown over time to millions of lines of code. The monolithic nature of their application led to them basically building very tightly coupled designs, and this tight coupling was coming in their way. It was resulting in them not being able to innovate as quickly as they wanted to. Bugs in one part of their application would require them to roll back the entire application.',\n",
       " \"So many engineers working on the same code base with millions of lines of code, bugs were not that uncommon. It was increasingly hard to ship features or even bug fixes on time. So they looked out for a solution and decided to go with the microservices approach. But then they started to face another set of problems. . . .That's where Kubernetes came in:) See the full video talk by Kunal Parmar, Senior Engineering Manager at Box: https://lnkd.in/etnJTbE\",\n",
       " 'I hope you all are #GoT fans here. . . Let me tell you the #Kubernetes story at HBO! The engineers started panicking as they knew the unpredictable traffic for the most anticipated Game of Thrones season seven premiere is going to be HUGE. One of the challenges they found out was the under-utilization of the deployed resources. Node.js code tends only to use a single CPU core. AWS EC2 instances that had excellent networking capabilities tended to be based on dual-core CPUs. As such, HBO was only using 50 percent of the deployed CPU capacity across its deployment.',\n",
       " 'The ability to spin up new instances on EC2 wasn\\'t quite as fast as what HBO needed. HBO also found that in times of peak demand for Game of Thrones, it was also running out of available IP addresses to help deliver the content to viewers. \"We went from not running a single service inside of a container to hosting all of Games of Thrones season 7 with Kubernetes,\" Illya Chekrygin, Senior Staff Engineer at HBO told the KubeCon audience. At last, the HBO chose Kubernetes among other alternatives, basically because of its vibrant and',\n",
       " \"active community. Credits: KubeCon 2017, eWEEK Italy's biggest traditional bank is embracing #Kubernetes ? A conventional bank running its real business on such a young technology? No way, are you kidding me? Nope, I am not kidding. Italy's banking group, Intesa Sanpaolo, has made this transition. These are banks who still run their ATM networks on 30-year-old mainframe technology, and embracing the hottest trend & tech is nearly unbelievable. Even though ING, the banking and financial corporation, changed the way the banks were seen by upgrading itself with Kubernetes and #DevOps practices very early in the game, there was still a stigma with adopting Kubernetes in the highly regulated and controlled environments like Healthcare, Banks, etc. The bank's engineering team came up with an initiative strategy in 2018 to throw away the old way of thinking and started embracing the technologies like microservices, container architecture, and migrate from monolithic to multi-tier applications. It was transforming itself into a software company, unbelievable. Today the bank runs more than 3,000 applications. Of those, more than 120 are now running in production using the new microservices architecture, including two of the 10 most business-critical for the bank.\",\n",
       " \"Read the full case here: https://lnkd.in/e_c5fbg How did 'Pokemon Go' able to scale so efficiently? The answer is #Kubernetes . Read the story. . . 500+ million downloads and 20+ million daily active users. That's HUGE. Pokemon Go engineers never thought their user base would increase exponentially surpassing the expectations within a short time. Even the servers couldn't handle this much traffic. The Challenge: The horizontal scaling on one side but Pokemon Go also faced a severe challenge when it came to vertical scaling because of the real-time activity by millions of users worldwide.\",\n",
       " \"Niantic was not prepared for this. The Solution: The magic of containers. The application logic for the game ran on Google Container Engine (GKE) powered by the open-source Kubernetes project. Niantic chose GKE for its ability to orchestrate their container cluster at planetary-scale, freeing its team to focus on deploying live changes for their players. In this way, Niantic used Google Cloud to turn Pokémon GO into a service for millions of players, continuously adapting and improving. This got them more time to concentrate on building the game's application logic and new features rather than worrying about the scaling part. “Going Viral” is not always easy to predict but you can always have Kubernetes in your tech stack.\",\n",
       " 'CI/CD with Kubernetes: How can you quickly achieve CI/CD automation with #Kubernetes and roll it out across your organization? Step 1: Develop your microservice using dependencies from registries that are proxied in Artifactory. The resulting App package can be a .war or .jar file. Step 2: Create a Docker Framework using Tomcat and Java-8 on Ubuntu as a base image. Push this image to a Docker registry in Artifactory, where it is also scanned by Xray to assure security and',\n",
       " 'license compliance. Step 3: Create the Docker image for the microservice by adding the .war/.jar file to the Docker Framework, and push the image to a Docker registry in Artifactory, where it is scanned by Xray. Step 4: Create a Helm chart for the microservice, and push it to a Helm repository in Artifactory. Step 5: Deploy the microservice from the secure Docker registry to the Kubernetes cluster using the Helm Chart. See the in-depth article: https://lnkd.in/e4Vkc3m Survey and findings: #Kubernetes usage in production is skyrocketing\\ue018 \\ue019\\ue01a\\ue01b\\ue01c\\ue01d\\ue01e\\ue01f',\n",
       " \"What else? Here are 15 interesting takeaways from the #CNCF annual survey. All information and source credit goes to CNCF - https://lnkd.in/eD9fN2R and Janakiram MSV's article here: https://lnkd.in/eb6GNZS Tips and tricks: #Kubernetes is the ultimate avatar of cloud-native development. Here are some tips and tricks shared by Timothy Josefik on HackerNoon. The whole article is here: https://lnkd.in/eGdmrkR #Kubernetes has become a synonym for #CloudNative tech. More and more companies are trying to use Kubernetes in production, and that's a good move. Take a look at these 10 Kubernetes production checklist. -----------------------------------------------------------------------------------------------------------------------------------------------------------------\",\n",
       " 'Free resources: Learn a new skill while working from home! Sharing some free #Kubernetes resources for everyone. > Kubernetes the hard way: https://lnkd.in/eu_rkry > Introduction to Kubernetes: https://lnkd.in/ebHEyaY > Learn Kubernetes by Playing the “Game of Pods”: https://lnkd.in/epGmpd9 > Kubernetes by example: https://lnkd.in/eETkYKW > Getting started with Kubernetes: https://lnkd.in/eqD8qWA > Kubernetes hands-on labs: https://lnkd.in/eEgfyDG > Learning path - Kubernetes: https://lnkd.in/ea5H-WH > Fundamentals of Containers, Kubernetes, and Red Hat OpenShift: https://lnkd.in/ea_tfrt > Zero to hero with Kubernetes: https://lnkd.in/eJJRjck That is it:) All credits to Kubernetes for helping companies scale and win big time.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'makes', 'it', 'easy', 'to', 'build', 'and', 'add', 'more', 'features', 'and', 'improving', 'the', 'application', 'to', 'attain', 'higher', 'customer', 'satisfaction.', 'Finally,', 'no', 'matter', 'what', 'technology', \"you're\", 'invested', 'in,', 'Kubernetes', 'can', 'help', 'you.', 'Image', 'credits:', 'Source:', 'Knoldus', 'Inc', 'What', 'is', 'the', 'Master', 'node', 'and', 'Worker', 'node', 'in', '#Kubernetes?', 'Explained', 'below,', '#Containerization', 'is', 'the', 'trend', 'that', 'is', 'taking', 'over', 'the', 'world,', 'allowing', 'firms', 'to', 'run', 'any', 'kind', 'of', 'different', 'applications', 'in', 'a', 'variety', 'of', 'different', 'environments.', 'To', 'keep', 'track', 'of', 'all', 'these', 'containers,', 'to', 'schedule,', 'to', 'manage,', 'and', 'to', 'orchestrate', 'them,', 'we', 'all', 'require', 'an', 'orchestration', 'tool.', 'Kubernetes', 'does', 'it']\n"
     ]
    }
   ],
   "source": [
    "#tokenize each chunk\n",
    "tokenized_chunks=[]\n",
    "for doc in concatenated_strings:\n",
    "    doc_tokens = doc.split()\n",
    "    tokenized_chunks.append(doc_tokens)\n",
    "\n",
    "print(tokenized_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test =\"Master and slave\"\n",
    "tokenized_query = query_test.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exponentially well. Kubernetes is a master-slave type of architecture. It operated with Master node and worker node principles. What exactly they do? Master Node: >The main machine that controls the nodes > Main entry point for all administrative tasks > It handles the orchestration of the worker nodes Worker Node: > It is a worker machine in Kubernetes (used to be known as a minion) > This machine performs the requested tasks. The Master Node controls each Node > Runs containers inside pods > This is where the Docker engine runs and takes care of downloading images and starting containers Know in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes- how-to-get-started/ #Containers are the de-facto deployment format of today. But where does #Kubernetes comes in the play? While tools such as #Docker provide the actual containers, we also need tools to take care of things such as replication, failovers, orchestration, and that is where Kubernetes comes into play. The Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only', \"It makes it easy to build and add more features and improving the application to attain higher customer satisfaction. Finally, no matter what technology you're invested in, Kubernetes can help you. Image credits: Source: Knoldus Inc What is the Master node and Worker node in #Kubernetes? Explained below, #Containerization is the trend that is taking over the world, allowing firms to run any kind of different applications in a variety of different environments. To keep track of all these containers, to schedule, to manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\", 'How to decide? Kubernetes is devised as a highly available cluster of computers that are connected to work as a single unit for more power and efficiency. The cluster forms the heart of Kubernetes: It can schedule and run containers across a group of machines, be they physical or virtual, on-premises or in the cloud. A Kubernetes cluster is formed out of 2 types of resources: > Master is coordinating the cluster > Nodes are where we run applications Kubernetes is still a bit of sophisticated technology and has a steep learning curve, even after a']\n"
     ]
    }
   ],
   "source": [
    "doc = bm25.get_top_n(tokenized_query,concatenated_strings, n=3)\n",
    "print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining FAISS and BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, top_k=3):\n",
    "    # Dense retrieval with FAISS\n",
    "    query_embedding = encoder([query])\n",
    "    D, I = index.search(np.array(query_embedding).astype('float32'), top_k)  # Top K results\n",
    "\n",
    "    # Sparse retrieval with BM25\n",
    "    tokenized_query = query.split(\" \")\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_indices = bm25_scores.argsort()[-top_k:][::-1]  # Get top K indices\n",
    "\n",
    "    # Combine results from both methods\n",
    "    faiss_results = [concatenated_strings[i] for i in I[0]]\n",
    "    bm25_results = [concatenated_strings[i] for i in bm25_indices]\n",
    "    \n",
    "    return {\n",
    "        \"faiss_results\": faiss_results,\n",
    "        \"bm25_results\": bm25_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faiss_results': ['Kubernetes For Everyone Kubernetes introduction and features How Kubernetes works? In Kubernetes, there is a master node and multiple worker nodes, each worker node can handle multiple pods. Pods are just a bunch of containers clustered together as a working unit. You can start designing your applications using pods. Once your pods are ready, you can specify pod definitions to the master node, and how many you want to deploy. From this point, Kubernetes is in control. It takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes starts new pods on a functioning worker node. This makes the process of managing the containers easy and simple.',\n",
       "  'exponentially well. Kubernetes is a master-slave type of architecture. It operated with Master node and worker node principles. What exactly they do? Master Node: >The main machine that controls the nodes > Main entry point for all administrative tasks > It handles the orchestration of the worker nodes Worker Node: > It is a worker machine in Kubernetes (used to be known as a minion) > This machine performs the requested tasks. The Master Node controls each Node > Runs containers inside pods > This is where the Docker engine runs and takes care of downloading images and starting containers Know in-depth concepts here in the original article: https://blog.risingstack.com/what-is-kubernetes- how-to-get-started/ #Containers are the de-facto deployment format of today. But where does #Kubernetes comes in the play? While tools such as #Docker provide the actual containers, we also need tools to take care of things such as replication, failovers, orchestration, and that is where Kubernetes comes into play. The Kubernetes API is a great tool for automating a deployment pipeline. Deployments are not only',\n",
       "  \"It makes it easy to build and add more features and improving the application to attain higher customer satisfaction. Finally, no matter what technology you're invested in, Kubernetes can help you. Image credits: Source: Knoldus Inc What is the Master node and Worker node in #Kubernetes? Explained below, #Containerization is the trend that is taking over the world, allowing firms to run any kind of different applications in a variety of different environments. To keep track of all these containers, to schedule, to manage, and to orchestrate them, we all require an orchestration tool. Kubernetes does it\"],\n",
       " 'bm25_results': ['Kubernetes For Everyone Kubernetes introduction and features How Kubernetes works? In Kubernetes, there is a master node and multiple worker nodes, each worker node can handle multiple pods. Pods are just a bunch of containers clustered together as a working unit. You can start designing your applications using pods. Once your pods are ready, you can specify pod definitions to the master node, and how many you want to deploy. From this point, Kubernetes is in control. It takes the pods and deploys them to the worker nods. If a worker node goes down, Kubernetes starts new pods on a functioning worker node. This makes the process of managing the containers easy and simple.',\n",
       "  'couple of years working with it, you’ll stillwonder if you got it all under control. But when your company asks you to decide on using and implementing Kubernetes, one question you will have is, deciding on the Kubernetes clusters. My friend Sander has written an amazing article on this, take a look - https://lnkd.in/eSC5vpa Kubernetes security: Keep your clusters updated with the latest #Kubernetes security patches. See how and why. . . Just like any application, Kubernetes is continuously updating new features and security updates. Hence, it is imperative that the underlying nodes and Kubernetes clusters need to be in parallel and up to date as well. The standard “zonal” KubernetesEngine clusters will have only one master node backing them, but you can create “regional” clusters that provide multi-zone feature, highly available masters.',\n",
       "  \"What else? Here are 15 interesting takeaways from the #CNCF annual survey. All information and source credit goes to CNCF - https://lnkd.in/eD9fN2R and Janakiram MSV's article here: https://lnkd.in/eb6GNZS Tips and tricks: #Kubernetes is the ultimate avatar of cloud-native development. Here are some tips and tricks shared by Timothy Josefik on HackerNoon. The whole article is here: https://lnkd.in/eGdmrkR #Kubernetes has become a synonym for #CloudNative tech. More and more companies are trying to use Kubernetes in production, and that's a good move. Take a look at these 10 Kubernetes production checklist. -----------------------------------------------------------------------------------------------------------------------------------------------------------------\"]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"master and slave\"\n",
    "hybrid_search(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
